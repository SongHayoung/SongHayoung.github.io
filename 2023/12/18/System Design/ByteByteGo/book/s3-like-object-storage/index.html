<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="[System Design] S3-like Object Storage"><meta name="keywords" content="System Design"><meta name="author" content="Song Hayoung"><meta name="copyright" content="Song Hayoung"><title>[System Design] S3-like Object Storage | SUMFIのBlog</title><meta name="robots" content="noindex"><link rel="shortcut icon" href="/songcon.ico"><link rel="stylesheet" href="/css/index.css?version=1.7.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.7.0"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css?version=1.7.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.js" defer></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><link rel="dns-prefetch" href="https://www.google-analytics.com"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-169368422-1', 'auto');
ga('send', 'pageview');</script><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"7LZ6OJ4D6C","apiKey":"9a84e13f74ea78c3fd54512c10139c56","indexName":"git blog","hits":{"per_page":10},"languages":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}.","hits_stats":"${hits} results found in ${time} ms"}},
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/rss2.xml" title="SUMFIのBlog" type="application/rss+xml">
</head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#S3-like-Object-Storage"><span class="toc-number">1.</span> <span class="toc-text">S3-like Object Storage</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Storage-System-101"><span class="toc-number">2.</span> <span class="toc-text">Storage System 101</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Terminology"><span class="toc-number">2.1.</span> <span class="toc-text">Terminology</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Step-1-Understand-the-Problem-and-Establish-Design-Scope"><span class="toc-number">3.</span> <span class="toc-text">Step 1 - Understand the Problem and Establish Design Scope</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Non-functional-requirements"><span class="toc-number">3.1.</span> <span class="toc-text">Non-functional requirements</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Back-of-the-envelope-estimation"><span class="toc-number">3.2.</span> <span class="toc-text">Back-of-the-envelope estimation</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Step-2-Propose-High-Level-Design-and-Get-Buy-In"><span class="toc-number">4.</span> <span class="toc-text">Step 2 - Propose High-Level Design and Get Buy-In</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#High-level-design"><span class="toc-number">4.1.</span> <span class="toc-text">High-level design</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Uploading-an-object"><span class="toc-number">4.2.</span> <span class="toc-text">Uploading an object</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Downloading-an-object"><span class="toc-number">4.3.</span> <span class="toc-text">Downloading an object</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Step-3-Design-Deep-Dive"><span class="toc-number">5.</span> <span class="toc-text">Step 3 - Design Deep Dive</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Data-store"><span class="toc-number">5.1.</span> <span class="toc-text">Data store</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#High-level-design-for-the-data-store"><span class="toc-number">5.1.1.</span> <span class="toc-text">High-level design for the data store</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Data-persistence-flow"><span class="toc-number">5.1.2.</span> <span class="toc-text">Data persistence flow</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#How-data-is-organized"><span class="toc-number">5.1.3.</span> <span class="toc-text">How data is organized</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Object-lookup"><span class="toc-number">5.1.4.</span> <span class="toc-text">Object lookup</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Updated-data-persistence-flow"><span class="toc-number">5.1.5.</span> <span class="toc-text">Updated data persistence flow</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Durability"><span class="toc-number">5.1.6.</span> <span class="toc-text">Durability</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Hardware-failure-and-failure-domain"><span class="toc-number">5.1.6.1.</span> <span class="toc-text">Hardware failure and failure domain</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Erasure-coding"><span class="toc-number">5.1.6.2.</span> <span class="toc-text">Erasure coding</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Correctness-verification"><span class="toc-number">5.1.7.</span> <span class="toc-text">Correctness verification</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Metadata-data-model"><span class="toc-number">5.2.</span> <span class="toc-text">Metadata data model</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Schema"><span class="toc-number">5.2.0.1.</span> <span class="toc-text">Schema</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Scale-the-bucket-table"><span class="toc-number">5.2.0.2.</span> <span class="toc-text">Scale the bucket table</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Scale-the-object-table"><span class="toc-number">5.2.0.3.</span> <span class="toc-text">Scale the object table</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Listing-objects-in-a-bucket"><span class="toc-number">5.3.</span> <span class="toc-text">Listing objects in a bucket</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Single-database"><span class="toc-number">5.3.1.</span> <span class="toc-text">Single database</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Distributed-databases"><span class="toc-number">5.3.2.</span> <span class="toc-text">Distributed databases</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Object-versioning"><span class="toc-number">5.4.</span> <span class="toc-text">Object versioning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Optimizing-uploads-of-large-files"><span class="toc-number">5.5.</span> <span class="toc-text">Optimizing uploads of large files</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Garbage-collection"><span class="toc-number">5.6.</span> <span class="toc-text">Garbage collection</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Step-4-Wrap-Up"><span class="toc-number">6.</span> <span class="toc-text">Step 4 - Wrap Up</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Chapter-Summary"><span class="toc-number">7.</span> <span class="toc-text">Chapter Summary</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="https://avatars3.githubusercontent.com/u/37806785?s=460&amp;u=8c68d685faf7c5280cfbd736a6b1730b55fb4203&amp;v=4"></div><div class="author-info__name text-center">Song Hayoung</div><div class="author-info__description text-center"></div><div class="follow-button"><a target="_blank" rel="noopener" href="https://www.linkedin.com/in/hayoung-song-9523b61bb/">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">11203</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">196</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">62</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">VISITED</div><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">Seoul Korea</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">Jeju Korea</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">British Columbia Canada</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">Boracay Philippines</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">三重　日本</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">大阪　日本</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">名古屋　日本</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">静岡　日本</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">札幌　日本</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">京都　日本</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">Bangkok Thailand</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://xxxx.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">SUMFIのBlog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a><a class="site-page" href="/about">About</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> Search</span></a></span></div><div id="post-info"><div id="post-title">[System Design] S3-like Object Storage</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-12-18</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/System-Design/">System Design</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/System-Design/System-Design-Interview/">System Design Interview</a><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">5.7k</span><span class="post-meta__separator">|</span><span>Reading time: 35 min</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h2 id="S3-like-Object-Storage"><a href="#S3-like-Object-Storage" class="headerlink" title="S3-like Object Storage"></a>S3-like Object Storage</h2><span id="more"></span>
<p>이 포스트에서는 Amazon Simple Storage Service(S3)와 유사한 오브젝트 스토리지 서비스를 설계한다. S3는 RESTful API 기반 인터페이스를 통해 오브젝트 스토리지를 제공하는 AWS 서비스다.</p>
<ul>
<li>2006월 6월 출시</li>
<li>S3는 2010년에 버전 관리, 버킷 정책, multi-part 업로드 지원 추가</li>
<li>2011년에 서버 사이드 암호화, 멀티 오브젝트 삭제, 오브젝트 만료 기능 추가</li>
<li>2013년까지 S3에 저장된 오브젝트가 2조개에 달한다고 알려짐</li>
<li>2014년과 2015년에 수명 주기 정책, 이벤트 알림, cross-region 복제 지원 도입</li>
<li>2021년에는 저장된 오브젝트가 100조개가 넘을 것이라고 알려짐</li>
</ul>
<h2 id="Storage-System-101"><a href="#Storage-System-101" class="headerlink" title="Storage System 101"></a>Storage System 101</h2><p>스토리지 시스템은 크게 3가지로 분류할 수 있다.</p>
<ul>
<li>Block storage</li>
<li>File storage</li>
<li>Object storage</li>
</ul>
<p><strong>Block storage</strong></p>
<p>블록 스토리지는 1960년대에 처음 등장했다. 서버에 물리적으로 연결된 하드 디스크 드라이브(HDD) 및 솔리드 스테이트 드라이브(SSD)와 같은 일반적인 저장 장치는 모두 블록 스토리지로 간주된다.</p>
<p>블록 스토리지는 원시 블록을 서버에 볼륨으로 제공한다. 이는 가장 유연하고 다양한 형태의 스토리지다. 서버는 원시 블록을 포맷해 파일 시스템으로 사용하거나 애플리케이션에 해당 블록의 제어권을 넘길 수 있다. 데이터베이스나 가상 머신 엔진과 같은 일부 애플리케이션은 이런 블록을 직접 관리해 성능을 최대한 끌어올리기도 한다.</p>
<p>블록 스토리지는 물리적으로 연결된 스토리지에만 국한되지 않는다. 블록 스토리지는 고속 네트워크를 통해 서버에 연결하거나 파이버 채널(Fibre Channel, FC), iSCSI와 같은 업계 표준 연결 프로토콜을 통해 서버에 연결할 수 있다. 개념적으로 네트워크 연결 블록 스토리지는 여전히 원시 블록을 제공한다. 서버 입장에서는 물리적으로 연결된 블록 스토리지와 동일하게 작동한다.</p>
<p><strong>File storage</strong></p>
<p>파일 스토리지는 블록 스토리지 위에 구축된다. 파일과 디렉토리를 더 쉽게 처리할 수 있도록 더 높은 수준의 추상화를 제공한다. 데이터는 계층적 디렉토리 구조 아래 파일로 저장된다. 파일 스토리지는 가장 일반적인 범용 스토리지 솔루션이다. 파일 스토리지는 SMB/CIFS 및 NFS와 같은 일반적인 파일 수준 네트워크 프로토콜을 사용해 많은 수의 서버에서 액세스할 수 있다. 파일 스토리지에 액세스하는 서버는 블록을 관리하고 볼륨을 포맷하는 등의 복잡한 작업을 처리할 필요가 없다. 파일 스토리지의 단순성 덕분에 조직 내에서 많은 수의 파일과 폴더를 공유할 수 있는 훌륭한 솔루션이다.</p>
<p><strong>Object storage</strong></p>
<p>오브젝트 스토리지는 새로운 개념이다. 높은 내구성, 방대한 규모, 저렴한 비용을 위해 성능을 희생하는 매우 신중한 절충안을 제시한다. 비교적 “콜드” 데이터를 대상으로 하며 주로 아카이브와 백업에 사용된다. 오브젝트 스토리지는 모든 데이터를 플랫 구조의 오브젝트로 저장한다. 계층적 디렉토리 구조는 없다. 데이터 액세스는 일반적으로 RESTful API를 통해 제공된다. 다른 스토리지 유형에 비해 상대적으로 느리다. 대부분의 퍼블릭 클라우드 서비스 제공 업체는 이런 오브젝트 스토리지를 제공한다.</p>
<p><strong>Comparison</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231218235828688.png" alt=""></p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th><strong>Block storage</strong></th>
<th><strong>File storage</strong></th>
<th><strong>Object storage</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Mutable Content</td>
<td>Y</td>
<td>Y</td>
<td>N (object versioning is supported, in-place update is not）</td>
</tr>
<tr>
<td>Cost</td>
<td>High</td>
<td>Medium to high</td>
<td>Low</td>
</tr>
<tr>
<td>Performance</td>
<td>Medium to high, very high</td>
<td>Medium to high</td>
<td>Low to medium</td>
</tr>
<tr>
<td>Consistency</td>
<td>Strong consistency</td>
<td>Strong consistency</td>
<td>Strong consistency [5]</td>
</tr>
<tr>
<td>Data access</td>
<td>SAS [6]/iSCSI/FC</td>
<td>Standard file access, CIFS/SMB, and NFS</td>
<td>RESTful API</td>
</tr>
<tr>
<td>Scalability</td>
<td>Medium scalability</td>
<td>High scalability</td>
<td>Vast scalability</td>
</tr>
<tr>
<td>Good for</td>
<td>Virtual machines (VM), high-performance applications like database</td>
<td>General-purpose file system access</td>
<td>Binary data, unstructured data</td>
</tr>
</tbody>
</table>
</div>
<h3 id="Terminology"><a href="#Terminology" class="headerlink" title="Terminology"></a>Terminology</h3><p>S3와 유사한 오브젝트 스토리지를 설계하려면 먼저 몇 가지 핵심 오브젝트 스토리지 개념을 이해해야 한다. </p>
<p><strong>Bucket</strong>. 객체를 위한 논리적 컨테이너. 버킷 이름은 전 세계적으로 고유하다. S3에 데이터를 업로드하려면 먼저 버킷을 만들어야 한다.</p>
<p><strong>Object</strong>. 오브젝트는 버킷에 저장하는 개별 데이터 조각이다. 여기에는 오브젝트 데이터(payload)와 메타데이터가 포함된다. 오브젝트 데이터는 저장하려는 모든 바이트 시퀀스가 될 수 있다. 메타데이터는 오브젝트를 설명하는 name-value 쌍의 집합이다.</p>
<p><strong>Versioning</strong>. 한 오브젝트의 여러 변형을 동일한 버킷에 보관하는 기능이다. 버킷 수준에서 활성화 된다. 이 기능을 통해 사용자는 실수로 삭제되거나 덮어쓴 오브젝트를 복구할 수 있다.</p>
<p><strong>Uniform Resource Identifier (URI)</strong>. 오브젝트 스토리지는 리소스, 즉 버킷과 오브젝트에 액세스할 수 있는 RESTful API를 제공한다. 각 리소스는 해당 URI로 고유하게 식별된다.</p>
<p><strong>Service-level agreement (SLA)</strong>. SLA는 서비스 제공업체와 클라이언트 간의 계약이다. 예를 들어 Amazon S3는 아래와 같은 SLA를 제공한다.</p>
<ul>
<li>여러 가용 영역에 걸쳐 99.999999999%의 오브젝트에 대한 내구성을 제공하도록 설계됨</li>
<li>가용 영역 전체가 파괴되는 경우에도 데이터가 복원됨</li>
<li>99.9%의 가용성을 위해 설계됨</li>
</ul>
<h2 id="Step-1-Understand-the-Problem-and-Establish-Design-Scope"><a href="#Step-1-Understand-the-Problem-and-Establish-Design-Scope" class="headerlink" title="Step 1 - Understand the Problem and Establish Design Scope"></a>Step 1 - Understand the Problem and Establish Design Scope</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Candidate: Which features should be included in the design?</span><br><span class="line">Interviewer: We would like you to design an S3-like object storage system with the following functionalities:</span><br><span class="line"></span><br><span class="line">- Bucket creation.</span><br><span class="line">- Object uploading and downloading.</span><br><span class="line">- Object versioning.</span><br><span class="line">- Listing objects in a bucket. It’s similar to the “aws s3 ls” command [8].</span><br><span class="line"></span><br><span class="line">Candidate: What is the typical data size?</span><br><span class="line">Interviewer: We need to store both massive objects (a few GBs or more) and a large number of small objects (tens of KBs,) efficiently.</span><br><span class="line"></span><br><span class="line">Candidate: How much data do we need to store in one year?</span><br><span class="line">Interviewer: 100 petabytes (PB).</span><br><span class="line"></span><br><span class="line">Candidate: Can we assume data durability is 6 nines (99.9999%) and service availability is 4 nines (99.99%)?</span><br><span class="line">Interviewer: Yes, that sounds reasonable.</span><br></pre></td></tr></table></figure>
<h3 id="Non-functional-requirements"><a href="#Non-functional-requirements" class="headerlink" title="Non-functional requirements"></a>Non-functional requirements</h3><ul>
<li>100PB의 데이터</li>
<li>데이터 내구성 : 99.9999%</li>
<li>서비스 가용성 : 99.99%</li>
<li>스토리지 효율성. 높은 수준의 안정성과 성능을 유지하면서 스토리지 비용을 절감해야 한다.</li>
</ul>
<h3 id="Back-of-the-envelope-estimation"><a href="#Back-of-the-envelope-estimation" class="headerlink" title="Back-of-the-envelope estimation"></a>Back-of-the-envelope estimation</h3><p>오브젝트 스토리지에는 디스크 용량이나 초당 디스크 IOPS(IO per second)에 병목 현상이 있을 수 있다. </p>
<ul>
<li>디스크 용량. 오브젝트가 아래 나열된 분포를 따른다고 가정한다.<ul>
<li>전체 오브젝트의 20%가 소형 개체다.(1MB 미만)</li>
<li>60%의 개체는 중간 크기 개체다.(1MB ~ 64MB)</li>
<li>20%는 대형 개체다.(64MB 이상)</li>
</ul>
</li>
<li>IOPS. 하나의 하드디스크(SATA interface, 7200rpm)가 초당 100~150회의 랜덤 탐색(100-150 IOPS)을 수행할 수 있다고 가정한다.</li>
</ul>
<p>이런 가정을 통해 시스템에서 보존할 수 있는 총 오브젝트 수를 추정할 수 있다. 계산을 단순화하기 위해 각 오브젝트 유형의 중간 크기(소형 0.5MB, 중형 32MB, 대형 200MB)를 사용한다. 스토리지 사용률이 40%라고 가정하면 다음과 같다.</p>
<ul>
<li>100PB = 100 <em> 1000 </em> 1000 MB = 10^11MB</li>
<li>10^11 <em> 0.4 / (0.2 </em> 0.5MB + 0.6 <em> 32MB + 0.2 </em> 200MB) = 0.68억 개의 오브젝트</li>
<li>오브젝트의 메타데이터 크기가 약 1KB라고 가정하면 모든 메타데이터 정보를 저장하려면 0.68TB의 공간이 필요하다.</li>
</ul>
<h2 id="Step-2-Propose-High-Level-Design-and-Get-Buy-In"><a href="#Step-2-Propose-High-Level-Design-and-Get-Buy-In" class="headerlink" title="Step 2 - Propose High-Level Design and Get Buy-In"></a>Step 2 - Propose High-Level Design and Get Buy-In</h2><p>디자인을 살펴보기 전에 오브젝트 스토리지에 영향을 미칠 수 있는 몇 가지 속성을 살펴보자.</p>
<p><strong>Object immutability</strong>. 오브젝트 스토리지와 다른 두 가지 유형의 스토리지 시스템의 주요 차이점 중 하나는 오브젝트 스토리지에 저장된 오브젝트가 불변이라는 점이다. 오브젝트를 삭제하거나 새 버전으로 완전히 교체할 수 있지만 증분 변경은 할 수 없다.</p>
<p><strong>Key-value store</strong>. 오브젝트 URI를 사용해 객체 데이터를 검색할 수 있다. 오브젝트 URI가 키이고 객체 데이터가 값이다.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Request:</span><br><span class="line">GET /bucket1/object1.txt HTTP/1.1</span><br><span class="line"></span><br><span class="line">Response:</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Content-Length: 4567</span><br><span class="line"></span><br><span class="line">[4567 bytes of object data]</span><br></pre></td></tr></table></figure>
<p><strong>Write once, read many times</strong>. 오브젝트 데이터의 데이터 액세스 패턴은 한번 쓰고 여러 번 읽는 방식이다. LinkedIn의 조사에 따르면 요청의 95%가 읽기 작업이라 한다.</p>
<p><strong>Support both small and large objects</strong>. 오브젝트 크기는 다양할 수 있으며 두 가지를 모두 지원해야 한다.</p>
<p>오브젝트 스토리지의 설계 철학은 UNIX 파일 시스템의 설계 철학과 매우 유사하다. UNIX에서는 로컬 파일 시스템에 파일을 저장할 때 파일 이름과 파일 데이터를 함께 저장하지 않는다. 대신 파일 이름은 “inode”라는 데이터 구조에 저장되고, 파일 데이터는 서로 다른 디스크 위치에 저장된다. 이 노드에는 파일 데이터의 디스크 위치를 가리키는 파일 블록 포인터 목록이 포함되어 있따. 로컬 파일에 액세스할 때는 먼저 이 노드에 있는 메타데이터를 가져온다. 그런 다음 실제 디스크 위치를 가리키는 파일 블록 포인터를 따라 파일 데이터를 읽는다.</p>
<p>오브젝트 스토리지도 비슷하게 작동한다. 이 노드는 모든 오브젝트 메타데이터를 저장하는 메타데이터 저장소가 된다. 하드 디스크는 오브젝트 데이터를 저장하는 데이터 저장소가 된다. UNIX 파일 시스템에서 inode는 파일 블록 포인터를 사용해 하드 디스크의 데이터 위치를 기록한다. 오브젝트 스토리지에서 메타데이터 스토어는 네트워크 요청을 통해 오브젝트의 ID를 사용해 데이터 스토어에서 해당 오브젝트 데이터를 찾는다. 아래는 UNIX 파일 시스템과 오브젝트 스토리지를 보여준다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231219001618973.png" alt=""></p>
<p>메타데이터와 오브젝트 데이터를 분리하면 설계가 간소화된다. 데이터 저장소에는 변경 불가능한 데이터가 들어 있고 메타데이터 저장소에는 변경 가능한 데이터가 들어있다. 이렇게 분리하면 이 두 구성요소를 독립적으로 구현하고 최적화할 수 있다. 아래는 버킷과 오브젝트의 모습을 보여준다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231219001716628.png" alt=""></p>
<h3 id="High-level-design"><a href="#High-level-design" class="headerlink" title="High-level design"></a>High-level design</h3><p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231219001729584.png" alt=""></p>
<p><strong>Load balancer</strong>. 여러 API 서버에 RESTful API 요청을 분산한다.</p>
<p><strong>API service</strong>. ID 및 액세스 관리 서비스, 메타데이터 서비스, 스토리지 저장소에 대한 원격 프로시저 호출을 오케스트레이션 한다. 이 서비스는 state less이므로 수평적으로 확장할 수 있다.</p>
<p><strong>Identity and access management (IAM)</strong>. 인증, 권한 부여 및 액세스 제어를 처리하는 중앙 집중식 공간이다. 인증은 사용자가 누구인지 확인하고, 권한 부여는 사용자가 누구인지에 따라 어떤 작업을 수행할 수 있는지 검증한다.</p>
<p><strong>Data store</strong>. 실제 데이터를 저장하고 검색한다. 모든 데이터 관련 작업은 오브젝트 ID(UUID)를 기반으로 한다.</p>
<p><strong>Metadata store</strong>. 오브젝트의 메타데이터를 저장한다.</p>
<p>메타데이터와 데이터 스토어는 논리적 구성 요소일 뿐이며 이를 구현하는 방법은 다양하다. 예를 들어, Ceph의 Rados 게이트웨이에는 독립형 메타데이터 저장소가 없다. 오브젝트 버킷을 포함한 모든 것이 하나 또는 여러 개의 Rados 오브젝트로 유지된다.</p>
<p>이제 고수준 설계에 대한 기본적인 이해를 마쳤으니, 오브젝트 스토리지에서 가장 중요한 몇 가지 워크플로우를 살펴보자.</p>
<ul>
<li>오브젝트 업로드</li>
<li>오브젝트 다운로드</li>
<li>오브젝트 버전 관리 및 버킷에 오브젝트 나열하기</li>
</ul>
<h3 id="Uploading-an-object"><a href="#Uploading-an-object" class="headerlink" title="Uploading an object"></a>Uploading an object</h3><p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231219002152953.png" alt=""></p>
<p>오브젝트를 저장하기 위해선 버킷이 있어야한다. 이 예에서는 먼저 “bucket-to-share”라는 이름의 버킷을 만든 다음 “script.txt”라는 파일을 버킷에 업로드한다.</p>
<ol>
<li>클라이언트는 “bucket-to-share”라는 이름의 버킷을 만들기 위해 HTTP PUT요청을 보낸다. 요청은 API 서비스로 전달된다.</li>
<li>API 서비스가 IAM을 호출해 사용자가 인증되어 있고 WRITE 권한이 있는지 확인한다.</li>
<li>API 서비스는 메타데이터 저장소를 호출해 메타데이터 데이터베이스에 버킷 정보가 포함된 항목을 만든다. 항목이 생성되면 성공 메세지가 클라이언트에 반환된다.</li>
<li>버킷이 생성된 후 클라이언트는 “script.txt”라는 이름의 오브젝트를 생성하기 위해 HTTP PUT 요청을 보낸다.</li>
<li>API 서비스는 사용자의 신원을 확인하고 사용자에게 버킷에 대한 WRITE 권한이 있는지 확인한다.</li>
<li>유효성 검사가 성공하면 API 서비스는 HTTP PUT 페이로드의 객체 데이터를 데이터 저장소로 보낸다. 데이터 저장소는 페이로드를 오브젝트로 보존하고 오브젝트의 UUID를 반환한다.</li>
<li>API 서비스는 메타데이터 저장소를 호출해 메타데이터 데이터베이스에 새 항목을 생성한다. 이 항목에는 object_id(UUID), bucket_id(오브젝트가 속한 버킷), object_name 등과 같은 중요한 메타데이터가 포함된다.</li>
</ol>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>object_name</strong></th>
<th><strong>object_id</strong></th>
<th><strong>bucket_id</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>script.txt</td>
<td>239D5866-0052-00F6-014E-C914E61ED42B</td>
<td>82AA1B2E-F599-4590-B5E4-1F51AAE5F7E4</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">PUT /bucket-to-share/script.txt HTTP/1.1</span><br><span class="line">Host: foo.s3example.org</span><br><span class="line">Date: Sun, 12 Sept 2021 17:51:00 GMT</span><br><span class="line">Authorization: authorization string</span><br><span class="line">Content-Type: text/plain</span><br><span class="line">Content-Length: 4567</span><br><span class="line">x-amz-meta-author: Alex</span><br><span class="line"></span><br><span class="line">[4567 bytes of object data]</span><br></pre></td></tr></table></figure>
<h3 id="Downloading-an-object"><a href="#Downloading-an-object" class="headerlink" title="Downloading an object"></a>Downloading an object</h3><p>버킷에는 디렉토리 계층 구조가 없다. 그러나 버킷 이름과 오브젝트 이름을 연결해 디렉토리 구조를 시뮬레이션하여 논리적 계층 구조를 만들 수 있다. 예를 들어, 오브젝트의 이름을 “script.txt” 대신 “bucket-to-share/script.txt”로 지정한다. 오브젝트를 가져오려면 GET 요청에 오브젝트 이름을 지정한다. 오브젝트를 다운로드하는 API는 다음과 같다.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">GET /bucket-to-share/script.txt HTTP/1.1</span><br><span class="line">Host: foo.s3example.org</span><br><span class="line">Date: Sun, 12 Sept 2021 18:30:01 GMT</span><br><span class="line">Authorization: authorization string</span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231219010724475.png" alt=""></p>
<p>앞서 언급했듯이 데이터 저장소는 오브젝트 이름을 저장하지 않으며 object_id(UUID)를 통한 오브젝트 작업만 지원한다. 오브젝트를 다운로드하려면 먼저 오브젝트 이름을 UUID에 매핑해야 한다. 오브젝트를 다운로드하는 워크플로우는 아래와 같다.</p>
<ol>
<li>클라이언트가 로드 밸런서에 HTTP GET 요청을 보낸다. GET /bucket-to-share/script.txt</li>
<li>API 서비스는 IAM에 사용자가 버킷에 대한 읽기 엑세스 권한이 있는지 쿼리한다.</li>
<li>유효성이 확인되면 API 서비스는 메타데이터 스토어에서 해당 오브젝트의 UUID를 가져온다.</li>
<li>그런 다음, API 서비스는 데이터 저장소에서 해당 UUID로 오브젝트 데이터를 가져온다.</li>
<li>API 서비스는 클라이언트에게 HTTP GET 응답으로 오브젝트 데이터를 반환한다.</li>
</ol>
<h2 id="Step-3-Design-Deep-Dive"><a href="#Step-3-Design-Deep-Dive" class="headerlink" title="Step 3 - Design Deep Dive"></a>Step 3 - Design Deep Dive</h2><p>이번 섹션에서는 아래와 같은 내용을 다룬다.</p>
<ul>
<li>Data store</li>
<li>Metadata data model</li>
<li>Listing objects in a bucket</li>
<li>Object versioning</li>
<li>Optimizing uploads of large files</li>
<li>Garbage collection</li>
</ul>
<h3 id="Data-store"><a href="#Data-store" class="headerlink" title="Data store"></a>Data store</h3><p>데이터 저장소의 설계에 대해 자세히 살펴보자. 앞서 설명한 대로 API 서비스는 사용자의 외부 요청을 처리하고 이런 요청을 이행하기 위해 다양한 내부 서비스를 호출한다. 오브젝트를 유지하거나 검색하기 위해 API 서비스는 데이터 저장소를 호출한다. 아래는 오브젝트 업로드 및 다운로드를 위한 API 서비스와 데이터 저장소 간의 상호작용을 보여준다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231219224619307.png" alt=""></p>
<h4 id="High-level-design-for-the-data-store"><a href="#High-level-design-for-the-data-store" class="headerlink" title="High-level design for the data store"></a>High-level design for the data store</h4><p>데이터 스토어는 3개의 주요 컴포넌트를 지닌다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231219224712730.png" alt=""></p>
<p><strong>Data routing service</strong></p>
<p>데이터 라우팅 서비스는 데이터 노드 클러스터에 액세스하기 위한 RESTful 또는 gRPC API를 제공한다. 서버를 추가해 확장할 수 있는 stateless 서비스다. 이 서비스에는 아래와 같은 책임이 있다.</p>
<ul>
<li>할당 서비스를 쿼리해 데이터를 저장할 최적의 데이터 노드를 찾는다.</li>
<li>데이터 노드에서 데이터를 읽고 API 서비스로 반환한다.</li>
<li>데이터 노드에 데이터를 쓴다.</li>
</ul>
<p><strong>Placement service</strong></p>
<p>할당 서비스는 오브젝트를 저장하기 위해 어떤 데이터 노드(primary and replicas)를 선택해야 하는지 결정한다. 클러스터의 물리적 토폴로지를 제공하는 가상 클러스터 맵을 유지 관리한다. 가상 클러스터 맵에는 할당 서비스에서 복제본이 물리적으로 분리되어 있는지 확인하는데 사용하는 각 데이터 노드의 위치 정보가 포함되어 있다. 이런 분리는 높은 내구성의 핵심이다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231219224926322.png" alt=""></p>
<p>할당 서비스는 하트비트를 통해 모든 데이터 노드를 지속적으로 모니터링한다. 데이터 노드가 설정 가능한 15초의 유예 기간 내에 하트비트를 보내지 않으면, 할당 서비스는 가상 클러스터 맵에서 해당 노드를 “다운”으로 표시한다.</p>
<p>이는 매우 중요한 서비스이므로 Paxos 또는 Raft 합의 프로토콜을 사용해 5개 또는 7개의 할당 서비스 노드로 구성된 클러스터를 구축하는 것이 좋다. 합의 프로토콜은 절반 이상의 노드가 정상적으로 작동하는 한 서비스 전체가 계속 작동하도록 보장한다. 예를 들어, 할당 서비스 클러스터에 7개의 노드가 있는 경우 3개 노드의 장애를 견딜 수 있다. </p>
<p><strong>Data node</strong></p>
<p>데이터 노드는 실제 오브젝트 데이터를 저장한다. 복제 그룹이라고도 하는 여러 데이터 노드에 데이터를 복제해 안정성과 내구성을 보장한다. 각 데이터 노드에는 데이터 서비스 데몬이 실행된다. 데이터 서비스 데몬은 할당 서비스에 하트비트를 지속적으로 전송한다. 하트비트 메세지에는 다음과 같은 필수 정보가 포함된다.</p>
<ul>
<li>데이터 노드가 관리하는 디스크 드라이브(HDD, SDD) 수는 몇개인가</li>
<li>각 드라이브에 저장된 데이터의 양은 얼마인가?</li>
</ul>
<p>할당 서비스가 하트비트를 처음 수신하면 이 데이터 노드의 ID를 할당하고 가상 클러스터 맵에 추가한 후 다음 정보를 반환한다.</p>
<ul>
<li>데이터 노드의 고유 ID</li>
<li>가상 클러스터 맵</li>
<li>데이터를 복제할 위치</li>
</ul>
<h4 id="Data-persistence-flow"><a href="#Data-persistence-flow" class="headerlink" title="Data persistence flow"></a>Data persistence flow</h4><p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231219225327831.png" alt=""></p>
<p>이제 데이터가 데이터 노드에서 어떻게 유지되는지 살펴보자.</p>
<ol>
<li>API 서비스는 오브젝트 데이터를 데이터 저장소로 전달한다.</li>
<li>데이터 라우팅 서비스는 이 오브젝트에 대한 UUID를 생성하고 이 오브젝트를 저장할 데이터 노드에 대한 할당 서비스를 쿼리한다. 할당 서비스는 가상 클러스터 맵을 확인하고 primary 데이터 노드를 반환한다.</li>
<li>데이터 라우팅 서비스는 primary 데이터 노드에 UUID와 함께 데이터를 직접 전송한다.</li>
<li>primary 데이터 노드는 데이터를 로컬에 저장하고 두 개의 보조 데이터 노드에 복제한다. primary 노드는 데이터가 모든 보조 노드에 성공적으로 복제되면 데이터 라우팅 서비스에 응답한다.</li>
<li>오브젝트의 UUID(object_id)가 API 서비스로 반환된다.</li>
</ol>
<p>2단계에서 오브젝트의 UUID가 입력으로 주어지면 할당 서비스는 오브젝트에 대한 복제 그룹을 반환한다. 할당 서비스는 이 작업을 어떻게 수행할까? 이 조회는 결정론적이여야 하며, 복제 그룹이 추가되거나 제거되어도 살아남아야 한다는 점에 유의해야 한다. Concurrent hashing은 이런 조회 함수의 일반적인 구현이다.</p>
<p>4단계에서 primary 데이터 노드는 응답을 반환하기 전에 모든 보조 노드에 데이터를 복제한다. 이렇게 하면 모든 데이터 노드 간에 데이터 일관성이 강화된다. 이런 일관성에는 가장 느린 복제본이 완료될 때까지 기다려야 하기 때문에 대기 시간 비용이 발생한다. 아래는 일관성과 지연 시간 간의 장단점을 보여준다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231219225713472.png" alt=""></p>
<ol>
<li>세 노드가 모두 데이터를 저장하면 데이터가 성공적으로 저장된 것으로 간주된다. 이 방식은 일관성이 가장 뛰어나지만 지연 시간이 가장 길다.</li>
<li>primary 노드와 보조 노드 중 하나가 데이터를 저장한 후에 데이터가 성공적으로 저장된 것으로 간주된다. 이 방식은 일관성이 중간 정도이고 지연 시간이 중간 정도다.</li>
<li>primary 노드가 데이터를 저장한 후에 데이터가 성공적으로 저장된 것으로 간주한다. 이 접근 방식은 일관성이 가장 나쁘지만 지연 시간이 가장 짧다.</li>
</ol>
<p>2번과 3번은 최종 일관성의 형태이다.</p>
<h4 id="How-data-is-organized"><a href="#How-data-is-organized" class="headerlink" title="How data is organized"></a>How data is organized</h4><p>이제 각 데이터 노드가 데이터를 관리하는 방법을 살펴보자. 간단한 해결책은 각 객체를 독립형 파일에 저장하는 것이다. 이 방법은 효과가 있지만 작은 파일이 많으면 성능이 저하된다. 파일 시스템에 작은 파일이 너무 많으면 두 가지 문제가 발생한다. 첫째, 많은 데이터 블록이 낭비된다. 파일 시스템은 파일을 개별 디스크 블록에 저장한다. 디스크 블록은 크기가 동일하며 볼륨이 초기화될 때 크기가 고정된다. 일반적인 블록 크기는 약 4KB다. 4KB보다 작은 파일의 경우 여전히 전체 디스크 블록을 소비한다. 파일 시스템에 작은 파일이 많이 저장되어 있으면 디스크 블록을 많이 낭비하게 되고 각 블록은 작은 파일로만 가볍게 채워지게 된다.</p>
<p>둘째, 시스템의 inode 용량을 초과할 수 있다. 파일 시스템은 파일에 대한 위치 및 기타 정보를 inode라는 특수한 유형의 블록에 저장한다. 대부분의 파일 시스템에서 inode의 수는 디스크가 초기화될 때 고정된다. 작은 파일이 수백만 개에 달하면 모든 inode를 소모할 위험이 있다. 또한 운영체제는 파일 시스템 메타데이터를 적극적으로 캐싱하더라도 많은 수의 inode를 잘 처리하지 못한다. 이런 이유로 작은 오브젝트를 개별 파일로 저장하는 것은 실제로 잘 동작하지 못한다.</p>
<p>이런 문제를 해결하기 위해 여러 개의 작은 오브젝트를 큰 파일로 병합할 수 있다. 이것은 개념적으로 WAL(Write Ahead Log)처럼 동작한다. 오브젝트를 저장하면 기존의 read-write 파일에 추가된다. read-write 파일이 용량의 임계값(보통 몇 GB)에 도달하면 read-write파일은 read-only로 표시되고 새 오브젝트를 받기 위해 새 read-write이 만들어진다. 파일이 read-only로 표시되면 읽기 요청만 처리할 수 있다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231219232045977.png" alt=""></p>
<p>read-write 파일에 대한 쓰기 액세스는 직렬화되어야 한다. 아래서 볼 수 있듯이 오브젝트는 read-write파일에 차례대로 저장된다. 이 온디스크 레이아웃을 유지하려면 들어오는 쓰기 요청을 병렬로 처리하는 여러 코어가 차례대로 read-write파일에 써야한다. 많은 수의 코어가 많은 수신 요청을 병렬로 처리하는 최신 서버의 경우, 이는 쓰기 처리량을 심각하게 제한한다. 이 문제를 해결하기 위해 들어오는 요청을 처리하는 각 코어에 하나씩 전용 read-write 파일을 제공할 수 있다.</p>
<h4 id="Object-lookup"><a href="#Object-lookup" class="headerlink" title="Object lookup"></a>Object lookup</h4><p>각 데이터 파일에 여러 개의 작은 오브젝트가 포함되어 있는 경우, 데이터 노드는 UUID로 오브젝트를 어떻게 찾을 수 있을까? 데이터 노드에는 다음 정보가 필요하다.</p>
<ul>
<li>오브젝트가 포함된 데이터 파일</li>
<li>데이터 파일에 있는 오브젝트의 시작 오프셋</li>
<li>오브젝트의 크기</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231219232247448.png" alt=""></p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>Field</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>object_id</td>
<td>UUID of the object</td>
</tr>
<tr>
<td>file_name</td>
<td>The name of the file that contains the object</td>
</tr>
<tr>
<td>start_offset</td>
<td>Beginning address of the object in the file</td>
</tr>
<tr>
<td>object_size</td>
<td>The number of bytes in the object</td>
</tr>
</tbody>
</table>
</div>
<p>이 매핑을 저장하기 위한 두 가지 옵션, 즉 RocksDB와 같은 파일 기반 KV store 또는 관계형 데이터베이스를 고려해보자. RocksDB는 SSTable을 기반으로 하며, 쓰기에는 빠르지만 읽기에는 느리다. 관계형 데이터 베이스는 일반적으로 B+ tree 기반 스토리지 엔진을 사용하며 읽기에는 빠르지만 쓰기에는 느리다. 앞서 언급했듯이 데이터 액세스 패턴은 한번 쓰고 여러 번 읽는 방식이다. 관계형 데이터 베이스는 읽기 성능이 더 좋기 때문에 RocksDB보다 더 나은 선택이다.</p>
<p>이 관계형 데이터베이스를 어떻게 배포해야 할까? 우리 규모에서는 매핑 테이블의 데이터 볼륨이 방대하다. 모든 데이터 노드를 지원하기 위해 하나의 대규모 클러스터를 배포하는 것이 효과적일 수 있지만 관리가 어렵다. 이 매핑 데이터는 각 데이터 노드 내에 격리되어 있다는 점에 유의하자. 데이터 노드 간에 공유할 필요가 없다는 의미다. 이 속성을 활용하려면 각 데이터 노드에 간단한 관계형 데이터베이스를 배포하면 된다. 여기에는 SQLite가 좋은 선택이다.</p>
<h4 id="Updated-data-persistence-flow"><a href="#Updated-data-persistence-flow" class="headerlink" title="Updated data persistence flow"></a>Updated data persistence flow</h4><p>데이터 노드를 꽤 많이 변경했으므로 데이터 노드에 새 오브젝트를 저장하는 방법을 다시 살펴보자.</p>
<ol>
<li>API 서비스는 “object 4”라는 이름의 새 오브젝트를 저장하라는 요청을 보낸다.</li>
<li>데이터 노드 서비스는 “/data/c”라는 read-write 파일 끝에 “object 4”라는 오브젝트를 추가한다.</li>
<li>“object 4”의 새 레코드가 object_mapping 테이블에 삽입된다.</li>
<li>데이터 노드 서비스가 UUID를 API 서비스에 반환한다.</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231219232929778.png" alt=""></p>
<h4 id="Durability"><a href="#Durability" class="headerlink" title="Durability"></a>Durability</h4><p>데이터 안정성은 데이터 스토리지 시스템에서 매우 중요하다. 어떻게 하면 99.999%의 내구성을 제공하는 스토리지 시스템을 만들 수 있을까? 각 장애 사례를 신중하게 고려하고 데이터를 적절히 복제해야 한다.</p>
<h5 id="Hardware-failure-and-failure-domain"><a href="#Hardware-failure-and-failure-domain" class="headerlink" title="Hardware failure and failure domain"></a>Hardware failure and failure domain</h5><p>어떤 미디어를 사용하던 하드 드라이브 장애는 피할 수 없다. 일부 스토리지 미디어는 다른 미디어보다 내구성이 뛰어날 수 있지만, 내구성 목표를 달성하기 위해 단일 하드 드라이브에만 의존할 수는 없다. 내구성을 높이는 입증된 방법은 데이터를 여러 개의 하드 드라이브에 복제하여 하나의 디스크 장애가 전체 데이터 가용성에 영향을 미치지 않도록 하는 것이다. 우리 설계에서는 데이터를 세 번 복제한다.</p>
<p>회전식 하드 드라이브의 연간 장애율이 0.81%라고 가정하자. 이 수치는 모델과 제조업체에 따라 크게 달라진다. 데이터를 3번 복제하면 <code>1-(0.0081)^3 = ~0.999999</code>의 신뢰도를 얻을 수 있다. 이것은 매우 대략적인 추정치다.</p>
<p>완전한 내구성 평가를 위해서는 다양한 장애 도메인의 영향도 고려해야 한다. 장애 도메인은 중요한 서비스에 문제가 발생할 때 부정적인 영향을 받는 환경의 물리적 또는 논리적 섹션이다. 최신 데이터 센터에서 서버는 일반적으로 랙에 배치되며 랙은 rows / floors / rooms로 그룹화된다. 각 랙은 네트워크 스위치와 전원을 공유하기 때문에 랙의 모든 서버는 랙 수준의 장애 도메인에 속한다. 최신 서버는 마더보드, 프로세서, 전원 공급 장치, HDD 드라이브 등과 같은 구성 요소를 공유한다. 서버의 구성 요소는 노드 수준의 장애 도메인에 있다.</p>
<p>다음은 대규모 장애 도메인 격리에 좋은 예다. 일반적으로 데이터센터는 아무것도 공유하지 않는 인프라를 여러 가용 영역(Availavility Zones, AZ)으로 나눈다. 장애 영향을 최소화하기 위해 데이터를 서로 다른 AZ에 복제한다. 장애 도메인 수준을 선택한다고 해서 데이터의 내구성이 직접적으로 향상되는 것은 아니지만, 대규모 정전, 냉각 시스템 장애, 자연 재해 등과 같은 극단적인 상황에서 안정성이 향상된다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231219233518396.png" alt=""></p>
<h5 id="Erasure-coding"><a href="#Erasure-coding" class="headerlink" title="Erasure coding"></a>Erasure coding</h5><p>데이터 전체 복사본을 세 번 만들면 데이터의 내구성은 약 99.9999%다. 내구성을 더 높일 수 있는 다른 옵션이 있을까? erasure coding도 한가지 옵션이다. erasure coding은 데이터 내구성을 다르게 처리한다. 데이터를 더 작은 조각으로 나누고(서로 다른 서버에 배치) 중복성을 위해 패리티를 생성한다. 장애가 발생하면 청크 데이터와 패리티를 사용해 데이터를 재구성할 수 있다. 4 + 2 erasure coding의 예를 살펴보자.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231219233755317.png" alt=""></p>
<ol>
<li>데이터는 4개의 짝수 크기의 데이터 청크 d1,d2,d3,d4로 나뉜다.</li>
<li>수학 공식은 패리티 p1과 p2를 계산하는데 사용된다. 예를 들어 <code>p1 = d1 + 2 * d2 - d3 + 4 * d4, p2  -d1 + 5 * d2 + d3 - 3 * d4</code>다.</li>
<li>노드 충돌로 인해 데이터 d3와 d4가 손실되었다.</li>
<li>이 공식은 d1,d2,p1,p2의 값을 사용해 손실된 데이터 d3, d4를 재구성하는데 사용된다.</li>
</ol>
<p>아래 표시된 다른 예시를 통해 오류 도메인에서 erasure coding이 어떻게 작동하는지 살펴보자. 8 + 4 erasure coding 설정은 원본 데이터를 8개의 청크로 균등히 분할하고 4개의 패리티를 계산한다. 12개의 데이터 조각은 모두 동일한 크기를 갖는다. 12개의 데이터 청크는 모두 12개의 서로 다른 장애 도메인에 분산된다. erasure coding의 수학적 원리는 최대 4개의 노드가 다운되더라도 원본 데이터를 재구성할 수 있도록 보장한다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231219234047035.png" alt=""></p>
<p>데이터 라우터가 하나의 정상 노드에서 오브젝트에 대한 데이터만 읽으면 되는 복제와 달리 erasure coding에서는 데이터 라우터가 최소 8개의 정상 노드에서 데이터를 읽어야 한다. 이는 아키텍처 설계상의 트레이드 오프다. 내구성을 높이고 스토리지 비용을 낮추는 대신 액세스 속도가 느린 더 복잡한 솔루션을 사용한다. 스토리지가 주요 비용인 오브젝트 스토리지의 경우 이런 절충안이 가치가 있다.</p>
<p>erasure coding에는 얼마나 많은 추가 공간이 필요할까? 데이터 청크 두 개당 패리티 블록 하나가 필요하므로 스토리지 오버헤드는 50%다. 3copy 복제에서는 스토리지 오버헤드가 200%다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231219234232654.png" alt=""></p>
<p>erasure coding이 데이터 내구성을 높여줄까? 노드의 연간 장애율이 0.81%라고 가정해보자. Backblaze의 계산에 따르면 erasure coding은 11 9s의 내구성을 달성할 수 있다. 이 계산에는 복잡한 수학 식이 따르니 <a target="_blank" rel="noopener" href="https://www.backblaze.com/blog/cloud-storage-durability/">여기</a>를 참고한다.</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>Replication</th>
<th><strong>Erasure coding</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>durability</td>
<td>6 nines of durability (data copied 3 times)</td>
<td>11 nines of durability (8+4 erasure coding). <strong>Erasure coding wins</strong>.</td>
</tr>
<tr>
<td>Storage efficiency</td>
<td>200% storage overhead.</td>
<td>50% storage overhead. <strong>Erasure coding wins</strong>.</td>
</tr>
<tr>
<td>Compute resource</td>
<td>No computation. <strong>Replication wins.</strong></td>
<td>Higher usage of computation resources to calculate parities.</td>
</tr>
<tr>
<td>Write performance</td>
<td>Replicating data to multiple nodes. No calculation is needed. <strong>Replication wins.</strong></td>
<td>Increased write latency because we need to calculate parities before data is written to disk.</td>
</tr>
<tr>
<td>Read performance</td>
<td>In normal operation, reads are served from the same replica. Reads under a failure mode are not impacted because reads can be served from a non-fault replica. <strong>Replication wins.</strong></td>
<td>In normal operation, every read has to come from multiple nodes in the cluster. Reads under a failure mode are slower because the missing data must be reconstructed first.</td>
</tr>
</tbody>
</table>
</div>
<p>요약하자면 복제는 지연 시간에 민감한 애플리케이션에서 널리 채택되는 반면, erasure coding은 스토리지 비용을 최소화하기 위해 자주 사용된다. erasure coding은 비용 효율성과 내구성 면에서 매력적이지만 데이터 노드 설계를 크게 복잡하게 만든다. 따라서 이 설계에서는 주로 복제에 중점을 둔다.</p>
<h4 id="Correctness-verification"><a href="#Correctness-verification" class="headerlink" title="Correctness verification"></a>Correctness verification</h4><p>erasure coding은 비슷한 스토리지 비용으로 데이터 내구성을 높여준다. 이제 또 다른 어려운 과제인 데이터 손상을 해결할 수 있다.</p>
<p>디스크에 완전히 장애가 발생해 장애를 감지할 수 있는 경우, 이를 데이터 노드 장애로 처리할 수 있다. 이 경우 erasure coding을 사용해 데이터를 재구성할 수 있다. 그러나 인메모리 데이터 손상은 대규모 시스템에서 자주 발생하는 문제다. 이 문제는 프로세스 경계 사이에서 checksum을 확인해 해결할 수 있다. 체크섬은 데이터 오류를 감지하는데 사용되는 작은 크기의 데이터 블록이다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231219234739387.png" alt=""></p>
<p>원본 데이터의 체크섬을 알고 있으면 전송 후 데이터의 체크섬을 계산할 수 있다.</p>
<ul>
<li>서로 다르면 데이터가 손상된 것이다.</li>
<li>두 값이 같으면 데이터가 손상되지 않았을 확률이 매우 높다. 확률은 100%는 아니지만 실제로는 동일하다고 가정할 수 있다.</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231219234835242.png" alt=""></p>
<p>MD5, SHA1, HMAC 등과 같은 많은 체크섬 알고리즘이 있다. 좋은 체크섬 알고리즘은 일반적으로 입력값이 조금만 변경되어도 상당히 다른 값을 출력한다. 이 장에서는 MD5와 같은 간단한 체크섬 알고리즘을 선택한다.</p>
<p>우리 디자인에서는 각 객체의 끝에 체크섬을 추가한다. 파일을 읽기 전용으로 표시하기 전에 파일 전체에 대한 체크섬을 마지막에 추가한다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231219235039647.png" alt=""></p>
<p>(8 + 4) erasure coding과 체크섬 검증을 사용하면 데이터를 읽을 때 이런 일이 발생한다.</p>
<ol>
<li>오브젝트 데이터와 체크섬을 가져온다.</li>
<li>받은 데이터에 대해 체크섬을 계산한다.<ol>
<li>두 체크섬이 일치하면 데이터에 오류가 없는 것이다.</li>
<li>체크섬이 다르면 데이터가 손상된 것이다. 다른 장애 도메인에서 데이터를 읽어 복구를 시도한다.</li>
</ol>
</li>
<li>8개의 데이터가 모두 반환될 때까지 1단계와 2단계를 반복한다. 그런 다음 데이터를 재구성해 클라이언트로 다시 보낸다.</li>
</ol>
<h3 id="Metadata-data-model"><a href="#Metadata-data-model" class="headerlink" title="Metadata data model"></a>Metadata data model</h3><p>이 섹션에서는 먼저 데이터베이스 스키마에 대해 설명한 뒤 데이터베이스 확장에 대해 자세히 살펴본다.</p>
<h5 id="Schema"><a href="#Schema" class="headerlink" title="Schema"></a>Schema</h5><p>데이터베이스 스키마는 다음 3가지 쿼리를 지원해야 한다.</p>
<ul>
<li>Query 1 : 오브젝트 이름으로 객체 ID 찾기</li>
<li>Query 2 : 오브젝트 이름을 기준으로 오브젝트를 삽입 및 삭제</li>
<li>Query 3 : 동일한 접두사를 공유하는 버킷에 있는 오브젝트를 나열</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231220231023953.png" alt=""></p>
<h5 id="Scale-the-bucket-table"><a href="#Scale-the-bucket-table" class="headerlink" title="Scale the bucket table"></a>Scale the bucket table</h5><p>일반적으로 사용자가 만들 수 있는 버킷 수에는 제한이 있으므로 버킷 테이블의 크기는 작다. 고객이 100만 명이고 각 고객이 버킷을 10개씩 소유하며 각 레코드의 용량이 1KB라고 가정해보자. 즉 10GB(100만 <em> 10 </em> 1KB)의 저장 공간이 필요하다. 전체 테이블은 최신 데이터베이스 서버에 쉽게 들어갈 수 있다. 그러나 단일 데이터베이스 서버에는 모든 읽기 요청을 처리하기에 충분한 CPU 또는 네트워크 대역폭이 없을 수 있다. 이 경우 여러 데이터베이스 복제본에 읽기 부하를 분산시킬 수 있다.</p>
<h5 id="Scale-the-object-table"><a href="#Scale-the-object-table" class="headerlink" title="Scale the object table"></a>Scale the object table</h5><p>오브젝트 테이블은 오브젝트 메타데이터를 보유한다. 우리가 설계한 규모의 데이터 세트는 단일 데이터베이스 인스턴스에 맞지 않을 가능성이 높다. 샤딩을 통해 오브젝트 테이블을 확장할 수 있다.</p>
<p>한 가지 옵션은 동일한 버킷 아래의 모든 오브젝트가 하나의 샤드에 저장되도록 bucket_id를 기준으로 샤딩하는 것이다. 이 방법은 버킷에 수십억 개의 오브젝트가 포함될 수 있으므로 핫스팟 샤드가 발생하기 때문에 작동하지 않는다.</p>
<p>또 다른 옵션은 object_id로 샤딩하는 것이다. 이 샤딩 체계의 장점은 부하를 균등하게 분산시킨 다는 것이다. 하지만 쿼리 1과 쿼리 2는 URI를 기반으로 하기 때문에 효율적으로 실행할 수 없다.</p>
<p>우리는 버킷 이름과 오브젝트 이름의 조합으로 샤딩 하는 방법을 선택한다. 그 이유는 대부분의 메타데이터 작업이 URI로 오브젝트 ID를 찾거나 URI를 통해 오브젝트를 업로드하는 등 오브젝트 URI를 기반으로 하기 때문이다. 데이터를 균등하게 분배하기 위해 (bucket_id, object_id)의 해시를 샤딩 키로 사용할 수 있다.</p>
<p>이 샤딩 체계를 사용하면 처음 두 쿼리를 지원하는 것은 간단하지만 마지막 쿼리는 덜 명확하다.</p>
<h3 id="Listing-objects-in-a-bucket"><a href="#Listing-objects-in-a-bucket" class="headerlink" title="Listing objects in a bucket"></a>Listing objects in a bucket</h3><p>오브젝트 저장소는 파일 시스템처럼 계층 구조가 아닌 플랫 구조로 파일을 정렬한다. 오브젝트는 <code>s3://bucket-name/object-name</code> 포멧을 사용해 엑세스한다. 예를들어 <em>s3://mybucket/abc/d/e/f/file.txt</em> 에는 아래 내용이 포함된다.</p>
<ul>
<li>Bucket name : mybucket</li>
<li>Object name : abc/d/e/f/file.txt</li>
</ul>
<p>사용자가 버킷에서 오브젝트를 정리할 수 있도록 S3는 접두사라는 개념을 도입했다. 접두사는 오브젝트 이름의 시작 부분에 있는 문자열이다. S3는 접두사를 사용해 디렉토리와 유사한 방식으로 데이터를 구성한다. 그러나 접두사는 디렉토리가 아니다. 접두사를 기준으로 버킷을 나열하면 해당 접두사로 시작하는 오브젝트 이름으로만 결과가 제한된다.</p>
<p>위의 예에서 경로가 <code>s3://mybucket/abc/d/e/f/file.txt</code> 인 경우, 접두사는 <em>abc/d/e/f</em> 다.</p>
<p>AWS S3 listing 명령은 일반적으로 3가지 용도로 사용된다.</p>
<ul>
<li>사용자가 소유한 모든 버킷을 나열한다.</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws s3 list-buckets</span><br></pre></td></tr></table></figure>
<ul>
<li>지정된 접두사와 같은 레벨에 있는 버킷의 모든 오브젝트를 나열한다.</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws s3 ls s3://mybucket/abc/</span><br></pre></td></tr></table></figure>
<p>이 명령에서 접두사 뒤에 슬래시가 더 많이 붙은 이름이 있는 오브젝트가 공통 접두사로 롤업된다.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CA/cities/losangeles.txt</span><br><span class="line">CA/cities/sanfranciso.txt</span><br><span class="line">NY/cities/ny.txt</span><br><span class="line">federal.txt</span><br></pre></td></tr></table></figure>
<p>‘/‘ 접두사가 붙은 버킷을 나열하면 CA/ 및 NY/ 아래의 모든 항목이 이 버킷에 합쳐진 결과가 반환된다.<br>CA/ NY/ federal.txt</p>
<ul>
<li>동일한 접두사를 공유하는 버킷의 모든 오브젝트를 재귀적으로 나열한다.</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws s3 ls s3://mybucket/abc/ --recursive</span><br></pre></td></tr></table></figure>
<p>위와 같은 예로 버킷에 CA/ 접두사를 붙여 나열하면 이런 결과가 반환된다.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CA/cities/losangeles.txt</span><br><span class="line">CA/cities/sanfranciso.txt</span><br></pre></td></tr></table></figure>
<h4 id="Single-database"><a href="#Single-database" class="headerlink" title="Single database"></a>Single database</h4><p>먼저 단일 데이터베이스로 listing 명령을 지원하는 방법을 살펴보자. 사용자가 소유한 모든 버킷을 나열하려면 다음 쿼리를 실행한다.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM bucket WHERE owner_id=&#123;id&#125;</span><br></pre></td></tr></table></figure>
<p>버킷에서 동일한 접두사를 공유하는 모든 오브젝트를 나열하려면 다음과 같은 쿼리를 실행한다.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM object WHERE bucket_id = &quot;123&quot; AND object_name LIKE `abc/%`</span><br></pre></td></tr></table></figure>
<p>이 예에서 접두사 “abc/“를 공유하는 bucket_id가 “123”인 모든 오브젝트를 찾는다. 지정된 접두사 뒤에 슬래시가 더 많이 포함된 모든 오브젝트는 앞서 사용 사례 2에서 설명한 대로 애플리케이션 코드에서 롤업된다.</p>
<p>동일한 쿼리는 앞서 사용 사례 3에서 설명한 대로 재귀 목록 모드를 지원한다. 애플리케이션 코드는 롤업을 수행하지 않고도 동일한 접두사를 공유하는 모든 오브젝트를 나열한다.</p>
<h4 id="Distributed-databases"><a href="#Distributed-databases" class="headerlink" title="Distributed databases"></a>Distributed databases</h4><p>메타데이터 테이블이 샤드화되면 어떤 샤드에 데이터가 포함되어 있는지 알 수 없기 때문에 리스팅 기능을 구현하기 어렵다. 가장 확실한 해결책은 모든 샤드에서 검색 쿼리를 실행한 다음 결과를 집계하는 것이다.</p>
<ol>
<li>메타데이터 서비스는 다음을 실행해 모든 샤드에 쿼리한다.</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM object WHERE bucket_id = “123” AND object_name LIKE `a/b/%`</span><br></pre></td></tr></table></figure>
<ol>
<li>메타데이터 서비스는 각 샤드에서 반환된 모든 오브젝트를 집계해 그 결과를 호출자에게 반환한다.</li>
</ol>
<p>이 솔루션은 효과가 있지만 페이지네이션을 구현하는 것은 약간 복잡하다. 그 이유를 설명하기 전에 단일 데이터베이스가 있는 간단한 사례에서 페이지네이션이 어떻게 작동하는지 살펴보자. 각 페이지에 10개씩의 오브젝트가 있는 목록 페이지를 반환하려면 SELECT 쿼리는 다음과 같이 시작된다.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM object WHERE</span><br><span class="line">bucket_id = &quot;123&quot; AND object_name LIKE `a/b/%`</span><br><span class="line">ORDER BY object_name OFFSET 0 LIMIT 10</span><br></pre></td></tr></table></figure>
<p>오프셋과 리밋은 결과를 처음 10개 오브젝트로 제한한다. 다음 호출에서 사용자는 힌트와 함께 요청을 서버로 보내므로 서버는 두 번째 페이지에 대한 쿼리를 OFFSET 10으로 구성해야 한다는 것을 알 수 있다. 이 힌트는 일반적으로 서버가 각 페이지와 함께 클라이언트에 반환하는 커서를 사용해 수행된다. 오프셋 정보는 커서에 인코딩된다. 클라이언트는 다음 페이지에 대한 요청에 커서를 포함한다. 서버는 커서를 디코딩하고 커서에 포함된 오프셋 정보를 사용해 다음 페이지에 대한 쿼리를 구성한다. 위의 예제를 계속 진행하면 두 번째 페이지에 대한 쿼리는 다음과 같다.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM metadata</span><br><span class="line">WHERE bucket_id = &quot;123&quot; AND object_name LIKE `a/b/%`</span><br><span class="line">ORDER BY object_name OFFSET 10 LIMIT 10</span><br></pre></td></tr></table></figure>
<p>이 클라이언트-서버 요청 루프는 서버가 전체 목록의 끝을 표시하는 특수 커서를 반환할 때까지 계속된다.</p>
<p>이제 샤드 데이터베이스에 페이지네이션을 지원하는 것이 왜 복잡한지 살펴보자. 오브젝트가 여러 샤드에 분산되어 있기 때문에 샤드는 다양한 수의 결과를 반환할 수 있다. 어떤 샤드에는 10개 오브젝트의 전체 페이지가 포함될 수도 있고, 어떤 샤드에는 일부만 포함되거나 비어 있을 수도 있다. 애플리케이션 코드는 모든 샤드에서 결과를 수신하고, 집계 및 정렬한 다음, 예제에서는 10개의 페이지만 반환한다. 현재 라운드에 포함되지 않은 오브젝트는 다음 라운드에서 다시 고려해야 한다. 이는 각 샤드가 다른 오프셋을 가질 가능성이 높다는 것을 의미한다. 서버는 모든 샤드의 오프셋을 추적하고 해당 오프셋을 커서에 연결해야 한다. 샤드가 수백 개라면 추적해야 할 오프셋도 수백 개가 될 것이다.</p>
<p>이 문제를 해결할 수 있는 솔루션이 있지만 몇 가지 장단점이 있다. 오브젝트 스토리지는 방대한 규모와 높은 내구성에 맞춰져 있기 때문에 오브젝트 리스팅 성능이 우선순위가 되는 경우는 드물다. 실제로 모든 상용 오브젝트 스토리지는 최적화되지 않은 성능으로 오브젝트 리스팅을 지원한다. 이 점을 활용하기 위해 리스팅 데이터를 버킷ID 별로 샤딩된 별도의 테이블로 비정규화할 수 있다. 이 테이블은 오브젝트를 정렬하는 데만 사용된다. 이 설정을 사용하면 수십억 개의 오브젝트가 있는 버킷도 적절한 성능을 제공할 수 있다. 이렇게 하면 리스팅 쿼리가 단일 데이터베이스로 격리되어 구현이 크게 간소화된다.</p>
<h3 id="Object-versioning"><a href="#Object-versioning" class="headerlink" title="Object versioning"></a>Object versioning</h3><p>버전 관리란 한 오브젝트의 여러 버전을 버킷에 보관하는 기능이다. 버전 관리를 사용하면 실수로 삭제하거나 덮어 쓴 오브젝트를 복원할 수 있다. 예를 들어, 문서를 수정한 후 같은 버킷에 같은 이름으로 저장할 수 있다. 버전 관리가 없으면 문서 메타데이터의 이전 버전이 메타데이터 저장소의 새 버전으로 대체된다. 이전 버전의 문서는 삭제된 것으로 표시되므로 가비지 컬렉터가 해당 저장 공간을 회수한다. 버전 관리를 사용하면 오브젝트 스토어는 문서의 모든 이전 버전을 메타데이터 저장소에 보관하며, 이전 버전의 문서는 오브젝트 스토어에서 삭제된 것으로 표시되지 않는다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231220233259244.png" alt=""></p>
<ol>
<li>클라이언트는 “script.txt”라는 이름의 오브젝트를 업로드하기 위해 HTTP PUT 요청을 보낸다.</li>
<li>API 서비스는 사용자의 신원을 확인하고 사용자에게 버킷에 대한 WRITE 권한이 있는지 확인한다.</li>
<li>확인이 완료되면 API 서비스는 데이터를 데이터 저장소에 업로드한다. 데이터 저장소는 데이터를 새 오브젝트로 보존하고 새 UUID를 API 서비스에 반환한다.</li>
<li>API 서비스는 메타데이터 저장소를 호출해 이 오브젝트의 메타데이터 정보를 저장한다.</li>
<li>버전 관리를지원하기 위해 메타데이터 저장소의 오브젝트 테이블에는 버전 관리가 활성화된 경우에만 사용되는 object_version이라는 컬럼이 있다. 기존 레코드를 덮어쓰는 대신 새 레코드가 기존 레코드와 버킷 ID 및 오브젝트 이름은 동일하지만 오브젝트 ID 및 오브젝트 버전이 새로 삽입된다. object_id는 3단계에서 반환된 새 오브젝트의 UUID다. object_version은 새 행이 삽입될 때 생성되는 TIMEUUID 다. 메타데이터 저장소로 어떤 데이터베이스를 선택하든 오브젝트의 현재 버전을 조회하는 것이 효율적이어야 한다. 현재 버전은 동일한 object_name을 가진 모든 항목 중 가장 큰 TIMEUUID를 가진다. </li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231220233612698.png" alt=""></p>
<p>버전이 지정된 오브젝트를 업로드하는 것 외에도 삭제할 수도 있다. 오브젝트를 삭제하면 아래와 같이 모든 버전이 버킷에 남아 있고 삭제 마커를 삽입한다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231220233647121.png" alt=""></p>
<p>삭제 마커는 오브젝트의 새 버전이며, 삽입되면 오브젝트의 현재 버전이 된다. 오브젝트의 현재 버전이 삭제 마커일 때 GET 요청을 수행하면 404 오브젝트를 찾을 수 없음 오류가 반환된다.</p>
<h3 id="Optimizing-uploads-of-large-files"><a href="#Optimizing-uploads-of-large-files" class="headerlink" title="Optimizing uploads of large files"></a>Optimizing uploads of large files</h3><p>Back-of-the-envelope estimation에서 20%의 오브젝트가 큰 용량을 차지하는 것으로 추정했다. 일부는 몇 GB보다 클 수도 있다. 이렇게 큰 오브젝트 파일을 직접 업로드할 수도 있지만 시간이 오래 걸릴 수 있다. 업로드 도중에 네트워크 연결이 실패하면 처음부터 다시 시작해야 한다. 더 나은 해결책은 큰 오브젝트를 작은 부분으로 분할해 독립적으로 업로드하는 것이다. 모든 파트가 업로드되면 오브젝트 저장소가 파트에서 오브젝트를 다시 조립한다. 이 프로세스를 multi-part upload라고 한다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231220233931182.png" alt=""></p>
<ol>
<li>클라이언트는 오브젝트 스토어를 호출해 멀티파트 업로드를 시작한다.</li>
<li>데이터 스토어는 업로드를 고유하게 식별하는 uploadID를 반환한다.</li>
<li>클라이언트는 큰 파일을 작은 오브젝트로 분할하고 업로드를 시작한다. 파일 크기가 1.6GB이고 클라이언트가 이를 8개의 부분으로 분할해 각 부분의 크기가 200MB라고 가정해 보자. 클라이언트는 2단계에서 받은 uploadID와 함께 첫 번째 파트를 데이터 스토어에 업로드한다.</li>
<li>파트가 업로드되면 데이터 스토어는 기본적으로 해당 파트의 md5 체크섬인 ETag를 반환한다. 이 태그는 멀티 파트 업로드를 확인하는 데 사용된다.</li>
<li>모든 파트가 업로드되면 클라이언트는 업로드 ID, 파트 번호 및 ETag가 포함된 전체 멀티파트 업로드 요청을 전송한다.</li>
<li>데이터 저장소는 파트 번호를 기준으로 파트에서 오브젝트를 재조립한다. 오브젝트가 매우 크기 때문에 이 프로세스는 몇 분 정도 걸릴 수 있다. 재조립이 완료되면 클라이언트에 성공 메세지를 반환한다.</li>
</ol>
<p>이 접근 방식의 한 가지 문제점은 오브젝트를 재조립한 후에는 오래된 파트가 더 이상 유용하지 않다는 점이다. 이 문제를 해결하기 위해 더 이상 필요하지 않은 파트의 공간을 확보하는 가비지 컬렉션 서비스를 도입할 수 있다.</p>
<h3 id="Garbage-collection"><a href="#Garbage-collection" class="headerlink" title="Garbage collection"></a>Garbage collection</h3><p>가비지 컬렉션은 더 이상 사용되지 않는 저장 공간을 자동으로 회수하는 프로세스다. 데이터가 가비지가 되는 방법에는 몇 가지가 있다.</p>
<ul>
<li>지연된 오브젝트 삭제. 오브젝트가 실제로 삭제되지 않고 삭제 시점에 삭제 마크를 표시하는 경우다.</li>
<li>고아 데이터. 예를 들어, 반만 업로드된 데이터 또는 중단된 멀티 파트 업로드가 대상이다.</li>
<li>손상된 데이터. 체크섬 검증에 실패한 데이터.</li>
</ul>
<p>가비지 콜렉터는 데이터 스토어에서 오브젝트를 바로 제거하지 않는다. 삭제된 오브젝트는 압축 메커니즘을 통해 주기적으로 정리된다. 가비지 콜렉터는 복제본에서 사용되지 않는 공간을 회수하는 역할도 담당한다. 복제본의 경우, primary 노드와 백업 노드 모두에서 오브젝트를 삭제한다. Erasure coding의 경우 8 + 4 설정을 사용하면 12개 노드 모두에서 오브젝트를 삭제한다.</p>
<p>아래는 압축이 어떻게 작동하는지 보여주는 예시다.</p>
<ol>
<li>가비지 컬렉터는 “/data/b” 에서 “/data/d” 라는 새 파일로 오브젝트를 복사한다. 가비지 수집기는 “Object 2”와 “Object 5”를 건너 뛰는데 두 오브젝트에 대해 삭제 플래그가 모두 true로 설정되어 있기 때문이다.</li>
<li>모든 오브젝트가 복사된 후 가비지 컬렉터는 object_mapping 테이블을 업데이트한다. 예를 들어, “Object 3”의 obj_id 및 object_size 필드는 동일하게 유지되지만 file_name 및 start_offset은 새 위치를 반영하도록 업데이트된다. 데이터 일관성을 보장하려면 데이터베이스 트랜잭션에서 file_name 및 start_offset에 대한 업데이트 작업을 래핑하는 것이 좋다.</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231220235306592.png" alt=""></p>
<p>위에서 볼 수 있듯이 압축 후 새 파일의 크기는 이전 파일보다 작다. 작은 파일이 많이 생성되는 것을 방지하기 위해 가비지 컬렉터는 일반적으로 압축할 읽기 전용 파일이 많아질 때까지 기다렸다가 압축 프로세스를 통해 많은 읽기 전용 파일의 오브젝트를 몇 개의 큰 새 파일에 추가한다.</p>
<h2 id="Step-4-Wrap-Up"><a href="#Step-4-Wrap-Up" class="headerlink" title="Step 4 - Wrap Up"></a>Step 4 - Wrap Up</h2><p>이 포스트에서는 S3와 유사한 오브젝트 스토리지의 고수준 설계에 대해 설명했다. 블록 스토리지, 파일 스토리지, 오브젝트 스토리지의 차이점을 비교했다. 이 인터뷰의 초점은 오브젝트 스토리지의 설계에 맞춰져 있으므로 오브젝트의 업로드, 다운로드, 버킷에 오브젝트 리스팅 버전 관리가 일반적으로 오브젝트 스토리지에서 어떻게 이루어지는지 나열했다.</p>
<p>그런 다음 설계에 대해 더 자세히 살펴봤다. 오브젝트 스토리지는 데이터 저장소와 메타데이터 저장소로 구성된다. 데이터 저장소에 데이터가 어떻게 유지되는지 설명하고 안정성과 내구성을 높이기 위한 두 가지 방법, 즉 복제와 erasure coding에 대해 논의했다. 메타데이터 저장소의 경우 멀티파트 업로드가 실행되는 방식와 일반적인 사용 사례를 지원하기 위해 데이터베이스 스키마를 설계하는 방법을 설명했다. 마지막으로 메타데이터 저장소를 샤드해 더 큰 데이터 용량을 지원하는 방법을 설명했다.</p>
<h2 id="Chapter-Summary"><a href="#Chapter-Summary" class="headerlink" title="Chapter Summary"></a>Chapter Summary</h2><p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231220235811788.png" alt=""></p>
<!-- flag of hidden posts --></div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Song Hayoung</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://songhayoung.github.io/2023/12/18/System%20Design/ByteByteGo/book/s3-like-object-storage/">https://songhayoung.github.io/2023/12/18/System%20Design/ByteByteGo/book/s3-like-object-storage/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/System-Design/">System Design</a></div><nav id="pagination"></nav><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: '3604b61642355579f55e',
  clientSecret: 'f552120f18ac5aee3f6297e05e97d94c0a25cd4b',
  repo: 'SongHayoung.github.io',
  owner: 'SongHayoung',
  admin: 'SongHayoung',
  id: md5(decodeURI(location.pathname)),
  language: 'en'
})
gitalk.render('gitalk-container')</script></div></div><footer class="footer-bg" style="background-image: url(https://xxxx.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2020 - 2025 By Song Hayoung</div><div class="framework-info"><span>Driven - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">Learning how to walk slowly to not miss important things</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.7.0"></script><script src="/js/fancybox.js?version=1.7.0"></script><script src="/js/sidebar.js?version=1.7.0"></script><script src="/js/copy.js?version=1.7.0"></script><script src="/js/fireworks.js?version=1.7.0"></script><script src="/js/transition.js?version=1.7.0"></script><script src="/js/scroll.js?version=1.7.0"></script><script src="/js/head.js?version=1.7.0"></script><script src="/js/search/algolia.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="algolia-search"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>