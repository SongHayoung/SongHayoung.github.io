<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="[ByteByteGo] Why is Kafka so fast? How does it work?"><meta name="keywords" content="System Design"><meta name="author" content="Song Hayoung"><meta name="copyright" content="Song Hayoung"><title>[ByteByteGo] Why is Kafka so fast? How does it work? | SUMFIのBlog</title><meta name="robots" content="noindex"><link rel="shortcut icon" href="/songcon.ico"><link rel="stylesheet" href="/css/index.css?version=1.7.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.7.0"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css?version=1.7.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.js" defer></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><link rel="dns-prefetch" href="https://www.google-analytics.com"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-169368422-1', 'auto');
ga('send', 'pageview');</script><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"7LZ6OJ4D6C","apiKey":"9a84e13f74ea78c3fd54512c10139c56","indexName":"git blog","hits":{"per_page":10},"languages":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}.","hits_stats":"${hits} results found in ${time} ms"}},
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/rss2.xml" title="SUMFIのBlog" type="application/rss+xml">
</head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Why-is-Kafka-so-fast-How-does-it-work"><span class="toc-number">1.</span> <span class="toc-text">Why is Kafka so fast? How does it work?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka-Architecture-Distilled"><span class="toc-number">2.</span> <span class="toc-text">Kafka Architecture Distilled</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#The-Compute-Layer"><span class="toc-number">2.1.</span> <span class="toc-text">The Compute Layer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#The-Storage-Layer"><span class="toc-number">2.2.</span> <span class="toc-text">The Storage Layer</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Control-Plane"><span class="toc-number">2.2.1.</span> <span class="toc-text">Control Plane</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Data-Plane"><span class="toc-number">2.2.2.</span> <span class="toc-text">Data Plane</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Recod"><span class="toc-number">2.3.</span> <span class="toc-text">Recod</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Broker"><span class="toc-number">2.4.</span> <span class="toc-text">Broker</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Consumer-Group"><span class="toc-number">2.5.</span> <span class="toc-text">Consumer Group</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Transaction"><span class="toc-number">2.6.</span> <span class="toc-text">Transaction</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka-Optimizations"><span class="toc-number">3.</span> <span class="toc-text">Kafka Optimizations</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Compression-Serdes"><span class="toc-number">3.1.</span> <span class="toc-text">Compression Serdes</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Batching"><span class="toc-number">3.2.</span> <span class="toc-text">Batching</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Sequential-I-O"><span class="toc-number">3.3.</span> <span class="toc-text">Sequential I&#x2F;O</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Zero-Copy"><span class="toc-number">3.4.</span> <span class="toc-text">Zero-Copy</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Summary"><span class="toc-number">4.</span> <span class="toc-text">Summary</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="https://avatars3.githubusercontent.com/u/37806785?s=460&amp;u=8c68d685faf7c5280cfbd736a6b1730b55fb4203&amp;v=4"></div><div class="author-info__name text-center">Song Hayoung</div><div class="author-info__description text-center"></div><div class="follow-button"><a target="_blank" rel="noopener" href="https://www.linkedin.com/in/hayoung-song-9523b61bb/">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">10798</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">193</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">61</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">VISITED</div><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">Seoul Korea</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">Jeju Korea</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">British Columbia Canada</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">Boracay Philippines</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">三重　日本</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">大阪　日本</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">名古屋　日本</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">静岡　日本</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">札幌　日本</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">京都　日本</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">Bangkok Thailand</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://xxxx.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">SUMFIのBlog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a><a class="site-page" href="/about">About</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> Search</span></a></span></div><div id="post-info"><div id="post-title">[ByteByteGo] Why is Kafka so fast? How does it work?</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-09-15</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/System-Design/">System Design</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/System-Design/Byte-Byte-Go/">Byte Byte Go</a><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">1.4k</span><span class="post-meta__separator">|</span><span>Reading time: 8 min</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h2 id="Why-is-Kafka-so-fast-How-does-it-work"><a href="#Why-is-Kafka-so-fast-How-does-it-work" class="headerlink" title="Why is Kafka so fast? How does it work?"></a>Why is Kafka so fast? How does it work?</h2><span id="more"></span>
<p>이번 포스트에서는 아래의 내용들에 대해 알아본다.</p>
<ul>
<li>Kafka의 아키텍처와 생산자, 브로커, 소비자와 같은 핵심 구성 요소</li>
<li>데이터 저장 및 복제를 최적화하는 Kafka의 방법</li>
<li>Kafka의 인상적인 처리량과 짧은 레이턴시를 가능하게 하는 최적화 기능</li>
</ul>
<h2 id="Kafka-Architecture-Distilled"><a href="#Kafka-Architecture-Distilled" class="headerlink" title="Kafka Architecture Distilled"></a>Kafka Architecture Distilled</h2><p>Kafka가 pub-sub 메세징 미들웨어로 사용되는 일반적인 시나리오에서는 생산자, 브로커, 소비자라는 세 가지 중요한 구성 요소가 있다. 생산자는 메세지 발신자이고 소비자는 메세지 수신자다. 브로커는 일반적이고 클러스터 모드로 배포되며, 들어오는 메세지를 처리하고 브로커 파티션에 써서 소비자가 읽을 수 있도록 한다.</p>
<p>Kafka는 이벤트 스트리밍 플랫폼으로 포지셔닝되어 있기 대문에 메세지 큐에서 자주 사용되는 “메세지” 라는 용어는 Kafka에서는 사용되지 않고 “이벤트”라 부른다.</p>
<p>아래 다이어그램은 Kafka의 아키텍처와 클라이언트 API 구조를 자세히 보여준다. 생산자, 소비자, 브로커가 여전히 아키텍처의 핵심이지만, 처리량이 많고 지연 시간이 짧은 Kafka를 구축하려면 더 많은 것이 필요하다는 것을 알 수 있다. </p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20230915165545601.png" alt=""></p>
<p>고수준의 관점에서 아키텍처에는 컴퓨팅 계층과 스토리지 계층이라는 두 가지 계층이 있다.</p>
<h3 id="The-Compute-Layer"><a href="#The-Compute-Layer" class="headerlink" title="The Compute Layer"></a>The Compute Layer</h3><p>컴퓨팅 계층 또는 처리 계층은 다양한 애플리케이션이 API를 통해 카프카 브로커와 통신할 수 있게 해준다. 생산자는 생산자 API를 사용한다. 데이터베이스와 같이 외부 시스템이 Kafka와 통신하고자 하는 경우 통합 API로 Kafka Connect도 제공한다.</p>
<p>소비자는 소비자 API를 통해 브로커와 대화한다. 검색 엔진이나 데이터베이스와 같은 다른 데이터 싱크로 이벤트를 라우팅하기 위해 Kafka Connect API를 사용할 수 있다. 또한 소비자는 Kafka Streams API로 스트리밍 처리를 수행할 수 있다. 무제한의 레코드 스트림을 처리하는 경우, KStream을 생성할 수 있다. 아래 코드 스니펫은 키와 값에 Serdes를 사용하여 “orders”라는 토픽에  대한 KStream을 생성한다. 변경 로그에서 최신 상태만 필요한 경우, KTable을 생성하여 상태를 유지할 수 있다. Kafka Streams를 사용하면 이벤트 스트림에서 집계, 필터링, 그룹화 및 조인을 수행할 수 있다.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">final KStreamBuilder builder = new KStreamBuilder();final KStream&lt;String, OrderEvent&gt; orderEvents = builder.stream(Serdes.String(), orderEventSerde, &quot;orders&quot;);</span><br></pre></td></tr></table></figure>
<p>Kafka Streams API는 Java 애플리케이션에서 잘 작동하지만, 애플리케이션에 포함시키지 않고 순수한 스트리밍 처리 작업을 배포하고 싶을때가 있다. 이 경우 스트림 처리에 최적화된 데이터베이스 클러스터인 ksqlDB를 사용할 수 있다. 또한 결과를 쿼리할 수 있는 REST API를 제공한다.</p>
<p>컴퓨팅 계층에서 다양한 API를 지원하므로 이벤트 스트림에서 수행하려는 작업을 매우 유연하게 체인화할 수 있다. 예를 들어 “orders” 토픽을 구독하고, 제품을 기준으로 주문을 집계한 다음, 다른 분석 애플리케이션이 처리를 위해 구독하고 있는 “ordersByProduct” 토픽에서 주문 카운트를 다시 Kafka로 전송할 수 있다.</p>
<h3 id="The-Storage-Layer"><a href="#The-Storage-Layer" class="headerlink" title="The Storage Layer"></a>The Storage Layer</h3><p>이 계층은 카프카 브로커로 구성된다. Kafka 브로커는 서버 클러스터에서 실행된다. 데이터는 서로 다른 토픽 내의 파티션에 저장된다. 토픽은 데이터베이스 테이블과 같으며, 토픽의 파티션은 클러스터 노드에 분산될 수 있다. 파티션 내에서 이벤트는 오프셋에 따라 엄격하게 정렬된다. 오프셋은 파티션 내에서 이벤트의 위치를 나타내며 단조롭게 증가한다. 브로커에서 지속되는 이벤트는 변경 불가능하고 추가 전용이며, 심지어 삭제도 삭제 이벤트로 모델링된다. 따라서 생산자는 순차적 쓰기만 처리하고 소비자는 순차적 읽기만 처리한다.</p>
<p>카프카 브로커의 책임에는 파티션 관리, 읽기 및 쓰기 처리, 파티션 복제 관리가 포함된다. 단순하게 설계되어 확장이 용이하다. 브로커 아키텍처에 대해 더 자세히 살펴보자.</p>
<p>Kafka 브로커는 클러스터 모드로 배포되므로 노드를 관리하는데 필요한 두 가지 구성 요소, 즉 control plane과 data plane이 있다.</p>
<h4 id="Control-Plane"><a href="#Control-Plane" class="headerlink" title="Control Plane"></a>Control Plane</h4><p>컨트롤 플레인은 카프카 클러스터의 메타데이터를 관리한다. 이전에는 컨트롤러를 관리하는 것이 Zookeeper였는데, 하나의 브로커가 컨트롤러로 선택되었다. 이제 Kafka는 KRaft라는 새로운 모듈을 사용해 컨트롤 플레인을 구현한다. 몇 개의 브로커가 컨트롤러로 선택된다.</p>
<p>클러스터 종속성에서 Zookeeper가 제거된 이유는 무엇일까? Zookeeper를 사용하면 두 가지 유형의 시스템을 별도로 유지 관리해야 하는데, 하나는 Zookeeper이고 다른 하나는 Kafka다. KRaft를 사용하면 한 가지 유형의 시스템만 유지 관리하면 되므로 구성과 배포가 이전보다 훨씬 쉬워진다. 또한 KRaft는 브로커에 메타데이터를 전파하는 데 더 효율적이다.</p>
<p>여기서 KRaft 합의에 대한 자세한 내용을 다루지는 않는다. 한 가지 기억해야 할 것은 컨트롤러와 브로커의 메타데이터 캐시가 카프카의 특별한 토픽을 통해 동기화된다는 것이다.</p>
<h4 id="Data-Plane"><a href="#Data-Plane" class="headerlink" title="Data Plane"></a>Data Plane</h4><p>데이터 플레인은 데이터 복제를 처리한다. 아래 다이어그램은 예시를 보여준다. “orders” 토픽의 파티션 0에는 3개의 브로커를 걸쳐 3개의 복제본이 저장되어 있다. 브로커 1의 파티션은 현재 데이터 오프셋이 4인 리더이고, 브로커 2와 3의 파티션은 오프셋이 2와 3인 팔로워다.</p>
<ul>
<li>Step 1 : 리더를 따라잡기 위해 팔로워 1은 오프셋이 2인 FetchRequest를 발행하고 팔로워 2는 오프셋이 3인 FetchRequest를 발행한다.</li>
<li>Step 2 : 리더는 그에 따라 두 팔로워에게 데이터를 전송한다.</li>
<li>Step 3 : 팔로워의 요청은 이전에 가져온 레코드의 수신을 암시적으로 확인할 수 있게 함으로 리더는 오프셋 2 이전의 레코드들을 커밋한다.</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20230915171357194.png" alt=""></p>
<h3 id="Recod"><a href="#Recod" class="headerlink" title="Recod"></a>Recod</h3><p>Kafka는 이벤트의 추상화로 Record 클래스를 사용한다. 바인딩되지 않은 이벤트 스트림은 여러 개의 레코드로 구성된다. 레코드에는 다음 네 가지 부분이 있다.</p>
<ol>
<li>Timestamp</li>
<li>Key</li>
<li>Value</li>
<li>Headers(optional)</li>
</ol>
<p>키는 순서 적용, 동일한 키를 가진 데이터의 정렬 및 데이터 보존에 사용된다. 키와 값은 직렬화기 및 역직렬화기(serdes)를 사용하여 인코딩 및 디코딩할 수 있는 바이트 배열이다.</p>
<h3 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a>Broker</h3><p>스토리지 계층으로 브로커에 대해 설명했다. 데이터는 토픽으로 구성되고 브로커에 파티션으로 저장된다. 이제 브로커가 어떻게 동작하는지 살펴보자.</p>
<ul>
<li>Step 1 : 프로듀서가 브로커에 요청을 보내면 브로커의 소켓 수신 버퍼에 먼저 도착한다.</li>
<li>Step 2 - 3 : 네트워크 스레드 중 하나가 소켓 수신 버퍼에서 요청을 가져와 공유 요청 대기열에 넣는다. 이 스레드는 특정 프로듀서 클라이언트에 바인딩된다.</li>
<li>Step 4 : Kafka의 I/O 스레드 풀이 요청 대기열에서 요청을 선택한다.</li>
<li>Step 5 - 6 : I/O 스레드가 데이터의 CRC를 검증하고 이를 커밋 로그에 추가한다. 커밋 로그는 디스크에 세그먼트 단위로 구성된다. 각 세그먼트에는 실제 데이터와 인덱스의 두 부분이 있다.</li>
<li>Step 7 : 프로듀서 요청은 복제를 위해 <code>purgatory structure</code>에 저장되어 다음 요청을 받기 위해 I/O 스레드를 확보할 수 있다.</li>
<li>Step 8 : 요청이 복제되면 purgatory에서 제거된다. 응답이 생성되어 응답 대기열에 넣는다.</li>
<li>Step 9 - 10 : 네트워크 스레드가 응답 대기열에서 응답을 선택하여 해당 소켓 송신 버퍼에 보낸다. 네트워크 스레드는 특정 클라이언트에 바인딩되어 있다는 점에 유의해야 한다. 요청에 대한 응답이 전송된 후에만 네트워크 스레드가 특정 클라이언트로부터 다른 요청을 받는다.</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20230915172025714.png" alt=""></p>
<p>네트워크 스레드는 제로 카피 전송을 사용해 데이터를 기본 파일에서 소켓 버퍼로 직접 이동한다. 이것이 카프카가 빠른 이유 중 하나다.</p>
<h3 id="Consumer-Group"><a href="#Consumer-Group" class="headerlink" title="Consumer Group"></a>Consumer Group</h3><p>소비자 그룹은 이벤트 처리를 확장하는 효율적인 방법이다. 이벤트를 병렬로 처리할 수 있도록 소비자 간에 부하를 균등하게 분산할 수 있다. 분배 단위는 파티션이므로 파티션은 그룹 내 소비자 중 한 명에게만 할당된다. 그룹에 새로 가입하거나 탈퇴하는 소비자가 있으면 부하가 재조정된다.</p>
<p>다양한 할당 전략이 있다. 예를 들어 범위 파티션 전략은 각 개별 토픽 레벨에서 파티션을 배포한다. 토픽 “orders”에는 소비자 1과 2에 할당된 두 개의 파티션이 있다. “payments” 토픽에는 소비자 1, 2, 3, 4에 할당되는 4개의 파티션이 있다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20230915172317264.png" alt=""></p>
<h3 id="Transaction"><a href="#Transaction" class="headerlink" title="Transaction"></a>Transaction</h3><p>데이터베이스를 다룰 때 트랜잭션을 원자 연산에 사용하므로, 이는 “all or nothing”을 의미한다. 카프카 트랜잭션은 정확한 일회성 시멘틱을 보장하며 동일한 결과를 얻을 수 있다. Kafka 브로커는 커밋된 오프셋을 기록함으로써 이를 수행한다. 커밋되지 않은 이벤트는 소비자에게 표시되지 않는다. 트랜잭션을 활성화하면 처리 오버헤드가 발생하므로 Kafka 트랜잭션의 커밋 주기를 신중하게 선택해야 한다는 점에 유의해야 한다.</p>
<h2 id="Kafka-Optimizations"><a href="#Kafka-Optimizations" class="headerlink" title="Kafka Optimizations"></a>Kafka Optimizations</h2><p>이제 Kafka가 짧은 지연 시간과 높은 처리량을 달성할 수 있는 이유에 대해 알아보자.</p>
<h3 id="Compression-Serdes"><a href="#Compression-Serdes" class="headerlink" title="Compression Serdes"></a>Compression Serdes</h3><p>Kafka는 데이터 바이트 배열로 전송하므로 데이터를 압축하기 위해 직력화기와 역직렬화기(serdes)를 선택할 수 있다. 예를 들어, Kafka Record에는 Avro serdes를 사용할 수 있다. 이렇게 하면 전송할 데이터의 크기가 크게 줄어든다.</p>
<h3 id="Batching"><a href="#Batching" class="headerlink" title="Batching"></a>Batching</h3><p>카프카는 “메세지 집합” 추상화를 기반으로 구축하여 많은 작은 입출력 작업을 회피한다. 이를 통해 생산자와 소비자는 이벤트를 일괄적으로 보내고 받을 수 있으며, 네트워크 왕복에 따른 오버헤드를 줄일 수 있다. 또한 브로커는 한 번에 하나의 이벤트를 추가하는 대신 이벤트 청크를 한 번에 추가한다. 이러한 간단한 최적화를 통해 속도가 크게 향상된다.</p>
<h3 id="Sequential-I-O"><a href="#Sequential-I-O" class="headerlink" title="Sequential I/O"></a>Sequential I/O</h3><p>Kafka 브로커가 추가 전용 이벤트 로그를 사용하여 디스크에 대한 순차적 액세스를 보장하는 방법에 대해 이야기했다. 생산자는 데이터를 순차적으로 쓰고 소비자는 데이터를 순차적으로 읽는다. 이는 디스크의 여러 다른 위치로 점프하는 랜덤 액세스보다 훨씬 빠르다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20230915174858505.png" alt=""></p>
<p>일괄 처리 및 순차적 I/O를 통해 Kafka는 I/O 작업을 효율적으로 수행하고 무작위 메세지 쓰기의 폭주하는 스트림을 선형 쓰기로 전환한다.</p>
<h3 id="Zero-Copy"><a href="#Zero-Copy" class="headerlink" title="Zero-Copy"></a>Zero-Copy</h3><p>브로커 아키텍처에서는 제로 카피 전송을 사용하여 디스크의 데이터를 소켓 버퍼에 직접 복사하는 네트워크 스레드에 대해 이야기했다. 아래 다이어그램은 자세한 내용을 보여준다.</p>
<ul>
<li>Step 1.1 - 1.3 : 생산자가 디스크에 데이터를 쓴다.</li>
<li>Step 2 : 소비자가 제로 카피 없이 데이터 읽기<ul>
<li>Step 2.1 : 데이터가 디스크에서 OS 캐시로 로드된다.</li>
<li>Step 2.2 : 데이터가 OS 캐시에서 Kafka 애플리케이션으로 복사된다.</li>
<li>Step 2.3 : Kafka 애플리케이션이 데이터를 소켓 버퍼에 복사한다.</li>
<li>Step 2.4 : 데이터가 소켓 버퍼에서 네트워크 카드로 복사된다.</li>
<li>Step 2.5 : 네트워크 카드가 소비자에게 데이터를 전송한다.</li>
</ul>
</li>
<li>Step 3 : 소비자가 제로 카피를 사용해 데이터 읽기<ul>
<li>Step 3.1 : 데이터가 디스크에서 OS 캐시로 로드된다.</li>
<li>Step 3.2 : OS 캐시는 sendfile() 명령어를 통해 데이터를 네트워크 카드에 직접 복사한다.</li>
<li>Step 3.3 : 네트워크 카드가 소비자에게 데이터를 보낸다.</li>
</ul>
</li>
</ul>
<p>제로 카피는 애플리케이션 컨텍스트와 커널 컨텍스트 사이에 여러 데이터 복사본을 저장하는 지름길이다. 이 접근 방식을 사용하면 시간이 약 65% 단축된다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20230915175647391.png" alt=""></p>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>이번 포스트에서는 Kafka의 아키텍처를 전체적으로 살펴봤다. 큰 틀에서 보면 Kafka는 API가 있는 컴퓨팅 레이어와 브로커가 있는 스토리지 레이어의 두 가지 계층으로 구성되어 있다. Kafka는 데이터 전송과 디스크 액세스를 최적화하여 높은 처리량을 달성하므로 빅데이터 애플리케이션을 위한 이상적인 이벤트 스트리밍 플랫폼이다.</p>
<!-- flag of hidden posts --></div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Song Hayoung</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://songhayoung.github.io/2023/09/15/System%20Design/ByteByteGo/private/why-is-kafka-so-fast-how-does-it-work/">https://songhayoung.github.io/2023/09/15/System%20Design/ByteByteGo/private/why-is-kafka-so-fast-how-does-it-work/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/System-Design/">System Design</a></div><nav id="pagination"></nav><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: '3604b61642355579f55e',
  clientSecret: 'f552120f18ac5aee3f6297e05e97d94c0a25cd4b',
  repo: 'SongHayoung.github.io',
  owner: 'SongHayoung',
  admin: 'SongHayoung',
  id: md5(decodeURI(location.pathname)),
  language: 'en'
})
gitalk.render('gitalk-container')</script></div></div><footer class="footer-bg" style="background-image: url(https://xxxx.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2020 - 2024 By Song Hayoung</div><div class="framework-info"><span>Driven - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">Learning how to walk slowly to not miss important things</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.7.0"></script><script src="/js/fancybox.js?version=1.7.0"></script><script src="/js/sidebar.js?version=1.7.0"></script><script src="/js/copy.js?version=1.7.0"></script><script src="/js/fireworks.js?version=1.7.0"></script><script src="/js/transition.js?version=1.7.0"></script><script src="/js/scroll.js?version=1.7.0"></script><script src="/js/head.js?version=1.7.0"></script><script src="/js/search/algolia.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="algolia-search"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>