<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="[System Design] Nearby Friends"><meta name="keywords" content="System Design"><meta name="author" content="Song Hayoung"><meta name="copyright" content="Song Hayoung"><title>[System Design] Nearby Friends | SUMFIのBlog</title><meta name="robots" content="noindex"><link rel="shortcut icon" href="/songcon.ico"><link rel="stylesheet" href="/css/index.css?version=1.7.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.7.0"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css?version=1.7.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.js" defer></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><link rel="dns-prefetch" href="https://www.google-analytics.com"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-169368422-1', 'auto');
ga('send', 'pageview');</script><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"7LZ6OJ4D6C","apiKey":"9a84e13f74ea78c3fd54512c10139c56","indexName":"git blog","hits":{"per_page":10},"languages":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}.","hits_stats":"${hits} results found in ${time} ms"}},
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/rss2.xml" title="SUMFIのBlog" type="application/rss+xml">
</head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Nearby-Friends"><span class="toc-number">1.</span> <span class="toc-text">Nearby Friends</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Step-1-Understand-the-Problem-and-Establish-Design-Scope"><span class="toc-number">2.</span> <span class="toc-text">Step 1 - Understand the Problem and Establish Design Scope</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Functional-requirements"><span class="toc-number">2.1.</span> <span class="toc-text">Functional requirements</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Non-functional-requirements"><span class="toc-number">2.2.</span> <span class="toc-text">Non-functional requirements</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Back-of-the-envelope-estimation"><span class="toc-number">2.3.</span> <span class="toc-text">Back-of-the-envelope estimation</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Step-2-Propose-High-Level-Design-and-Get-Buy-In"><span class="toc-number">3.</span> <span class="toc-text">Step 2 - Propose High-Level Design and Get Buy-In</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#High-level-design"><span class="toc-number">3.1.</span> <span class="toc-text">High-level design</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Proposed-design"><span class="toc-number">3.1.1.</span> <span class="toc-text">Proposed design</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Load-balancer"><span class="toc-number">3.1.2.</span> <span class="toc-text">Load balancer</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#RESTful-API-servers"><span class="toc-number">3.1.3.</span> <span class="toc-text">RESTful API servers</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Websocket-servers"><span class="toc-number">3.1.4.</span> <span class="toc-text">Websocket servers</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Redis-location-cache"><span class="toc-number">3.1.5.</span> <span class="toc-text">Redis location cache</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#User-database"><span class="toc-number">3.1.6.</span> <span class="toc-text">User database</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Location-history-database"><span class="toc-number">3.1.7.</span> <span class="toc-text">Location history database</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Redis-pub-sub-server"><span class="toc-number">3.1.8.</span> <span class="toc-text">Redis pub&#x2F;sub server</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Periodic-location-update"><span class="toc-number">3.2.</span> <span class="toc-text">Periodic location update</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#API-design"><span class="toc-number">3.3.</span> <span class="toc-text">API design</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Data-model"><span class="toc-number">3.4.</span> <span class="toc-text">Data model</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Location-cache"><span class="toc-number">3.4.1.</span> <span class="toc-text">Location cache</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Location-history-database-1"><span class="toc-number">3.4.2.</span> <span class="toc-text">Location history database</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Step-3-Design-Deep-Dive"><span class="toc-number">4.</span> <span class="toc-text">Step 3 - Design Deep Dive</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#How-well-does-each-component-scale"><span class="toc-number">4.1.</span> <span class="toc-text">How well does each component scale?</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#API-servers"><span class="toc-number">4.1.1.</span> <span class="toc-text">API servers</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#WebSocket-servers"><span class="toc-number">4.1.2.</span> <span class="toc-text">WebSocket servers</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#User-database-1"><span class="toc-number">4.1.3.</span> <span class="toc-text">User database</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Location-cache-1"><span class="toc-number">4.1.4.</span> <span class="toc-text">Location cache</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Redis-pub-sub-server-1"><span class="toc-number">4.1.5.</span> <span class="toc-text">Redis pub&#x2F;sub server</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Distributed-Redis-pub-sub-server-cluster"><span class="toc-number">4.1.5.1.</span> <span class="toc-text">Distributed Redis pub&#x2F;sub server cluster</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Scaling-considerations-for-Redis-pub-sub-servers"><span class="toc-number">4.1.5.2.</span> <span class="toc-text">Scaling considerations for Redis pub&#x2F;sub servers</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Operational-considerations-for-Redis-pub-sub-servers"><span class="toc-number">4.1.5.3.</span> <span class="toc-text">Operational considerations for Redis pub&#x2F;sub servers</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Adding-removing-friends"><span class="toc-number">4.2.</span> <span class="toc-text">Adding&#x2F;removing friends</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Users-with-many-friends"><span class="toc-number">4.3.</span> <span class="toc-text">Users with many friends</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Nearby-random-person"><span class="toc-number">4.4.</span> <span class="toc-text">Nearby random person</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Alternative-to-Redis-pub-sub"><span class="toc-number">4.5.</span> <span class="toc-text">Alternative to Redis pub&#x2F;sub</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Step-4-Wrap-Up"><span class="toc-number">5.</span> <span class="toc-text">Step 4 - Wrap Up</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Chapter-Summary"><span class="toc-number">6.</span> <span class="toc-text">Chapter Summary</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="https://avatars3.githubusercontent.com/u/37806785?s=460&amp;u=8c68d685faf7c5280cfbd736a6b1730b55fb4203&amp;v=4"></div><div class="author-info__name text-center">Song Hayoung</div><div class="author-info__description text-center"></div><div class="follow-button"><a target="_blank" rel="noopener" href="https://www.linkedin.com/in/hayoung-song-9523b61bb/">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">11228</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">196</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">62</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">VISITED</div><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">Seoul Korea</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">Jeju Korea</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">British Columbia Canada</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">Boracay Philippines</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">三重　日本</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">大阪　日本</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">名古屋　日本</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">静岡　日本</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">札幌　日本</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">京都　日本</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">Bangkok Thailand</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://xxxx.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">SUMFIのBlog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a><a class="site-page" href="/about">About</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> Search</span></a></span></div><div id="post-info"><div id="post-title">[System Design] Nearby Friends</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-11-14</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/System-Design/">System Design</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/System-Design/System-Design-Interview/">System Design Interview</a><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">4k</span><span class="post-meta__separator">|</span><span>Reading time: 24 min</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h2 id="Nearby-Friends"><a href="#Nearby-Friends" class="headerlink" title="Nearby Friends"></a>Nearby Friends</h2><span id="more"></span>
<p>이번 포스트에서는 “Nearby Friends”라는 새로운 모바일 앱 기능을 위한 확장 가능한 백엔드 시스템을 설계한다. 자신의 위치에 액세스할 수 있는 권한을 부여한 opt-in 사용자에게 모바일 클라이언트는 지리적으로 가까운 곳에 있는 친구 목록을 표시한다. </p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231114202012982.png" alt=""></p>
<h2 id="Step-1-Understand-the-Problem-and-Establish-Design-Scope"><a href="#Step-1-Understand-the-Problem-and-Establish-Design-Scope" class="headerlink" title="Step 1 - Understand the Problem and Establish Design Scope"></a>Step 1 - Understand the Problem and Establish Design Scope</h2><h3 id="Functional-requirements"><a href="#Functional-requirements" class="headerlink" title="Functional requirements"></a>Functional requirements</h3><ul>
<li>사용자는 모바일 앱에서 주변 친구를 볼 수 있어야 한다. 주변 친구 목록의 각 항목에는 거리와 마지막으로 업데이트 된 시간을 나타내는 타임스탬프가 있다.</li>
<li>주변 친구 목록은 몇 초마다 업데이트 되어야 한다.</li>
</ul>
<h3 id="Non-functional-requirements"><a href="#Non-functional-requirements" class="headerlink" title="Non-functional requirements"></a>Non-functional requirements</h3><ul>
<li>Low latency. 친구의 위치 업데이트를 너무 늦지 않게 받는 것이 중요하다.</li>
<li>Reliability. 시스템이 전반적으로 안정적이어야 하지만, 간혹 데이터 포인트가 손실되는 것은 허용된다.</li>
<li>Eventual consistency. 위치 데이터 저장소는 강력한 일관성이 필요하지 않다. 다른 복제본에서 위치 데이터를 수신하는 데 몇 초 정도 지연되는 것은 허용된다.</li>
</ul>
<h3 id="Back-of-the-envelope-estimation"><a href="#Back-of-the-envelope-estimation" class="headerlink" title="Back-of-the-envelope estimation"></a>Back-of-the-envelope estimation</h3><ul>
<li>주변 반경 5마일 내에 위치한 친구가 주변 친구로 정의된다.</li>
<li>위치 새로 고침 간격은 30초다. </li>
<li>평균적으로 매일 1억 명의 사용자가 이 기능을 사용한다.</li>
<li>동시 사용자 수가 DAU의 10% 이므로 동시 사용자 수는 100M이라고 가정한다.</li>
<li>평균적으로 사용자 한 명당 400명의 친구가 있다. 이들 모두가 주변 친구 기능을 사용한다고 가정한다.</li>
<li>앱은 페이지당 20명의 주변 친구를 표시하며 요청 시 더 많은 주변 친구를 로드할 수 있다.</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Calculate QPS</span><br><span class="line">- 100M DAU</span><br><span class="line">- Concurrent users : 10% * 100M = 10M</span><br><span class="line">- user report their locations every 30s</span><br><span class="line">- Location update QPS = 10M / 30 =~ 334,000</span><br></pre></td></tr></table></figure>
<h2 id="Step-2-Propose-High-Level-Design-and-Get-Buy-In"><a href="#Step-2-Propose-High-Level-Design-and-Get-Buy-In" class="headerlink" title="Step 2 - Propose High-Level Design and Get Buy-In"></a>Step 2 - Propose High-Level Design and Get Buy-In</h2><p>이 섹션에서는 아래 사항에 대해 살펴본다.</p>
<ul>
<li>High-level design</li>
<li>API design</li>
<li>Data model</li>
</ul>
<p>다른 챕터에서는 일반적으로 상위 수준 설계에 앞서 API 설계와 데이터 모델에 대해 논의한다. 하지만 이 문제에서는 모든 친구에게 위치 데이터를 푸시해야 하기 때문에 클라이언트와 서버 간의 통신 프로토콜이 간단한 HTTP 프로토콜이 아닐 수 있다. 고수준 설계를 이해하지 못하면 API가 어떻게 생겼는지 알기 어렵다. 따라서 먼저 고수준 디자인에 대해 살펴본다.</p>
<h3 id="High-level-design"><a href="#High-level-design" class="headerlink" title="High-level design"></a>High-level design</h3><p>고수준에서 이 문제는 효율적인 메세지 전달을 위한 설계가 필요하다. 개념적으로 사용자는 근처에 있는 모든 활성 친구로부터 위치 업데이트를 받기를 원한다. 이론적으로 수전히 P2P 방식으로, 즉 사용자가 주변에 있는 다른 모든 활성 친구와 지속적인 연결을 유지할 수 있다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231114203628104.png" alt=""></p>
<p>이 솔루션은 연결이 불안정하고 전력 소비 예산이 빠듯한 모바일 장치에는 실용적이지 않지만 일반적인 설계 방향에 대한 아이디어를 제시한다. 보다 실용적인 디자인은 공유 백엔드가 있는 아래와 같은 모습이다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231114203718284.png" alt=""></p>
<p>위 다이어그램에서 백엔드의 책임은 다음과 같다.</p>
<ul>
<li>모든 활성 사용자로부터 위치 업데이트를 수신한다.</li>
<li>각 위치 업데이트에 대해 수신해야 하는 모든 활성 친구를 찾아 해당 사용자의 디바이스로 전달한다.</li>
<li>두 사용자 간의 거리가 특정 임계값을 초과하는 경우 수신자의 디바이스로 전달하지 않는다.</li>
</ul>
<p>꽤 간단해 보이지만, 대규모로 이 작업을 수행하는 것은 쉽지 않다. 우리는 천만 명의 활성 사용자를 보유하고 있다. 각 사용자가 30초마다 위치 정보를 업데이트하면 초당 334,000건의 업데이트가 발생한다. 평균적으로 각 사용자에게 400명의 친구가 있고, 그 친구 중 약 10%가 온라인 상태이거나 근처에 있다고 가정하면 백엔드에서는 초당 334K <em> 400 </em> 10% = 초당 14M 건의 위치 업데이트를 전달한다. 이는 전달해야할 데이터 양이 엄청 많아 진다.</p>
<h4 id="Proposed-design"><a href="#Proposed-design" class="headerlink" title="Proposed design"></a>Proposed design</h4><p>아래는 기능적 요구 사항을 충족하는 기본 설계를 보여준다. 각 구성 요소를 살펴보자.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231114204224592.png" alt=""></p>
<h4 id="Load-balancer"><a href="#Load-balancer" class="headerlink" title="Load balancer"></a>Load balancer</h4><p>로드 밸런서는 RESTful API 서버와 상태 저장 양방향 웹소켓 서버 앞에 위치한다. 로드 밸런서는 이런 서버에 트래픽을 분산해 부하를 고르게 분산시킨다.</p>
<h4 id="RESTful-API-servers"><a href="#RESTful-API-servers" class="headerlink" title="RESTful API servers"></a>RESTful API servers</h4><p>이 요소는 일반적인 요청 / 응답 트래픽을 처리하는 상태 비저장 HTTP 서버의 클러스터다. API 요청 흐름은 아래 표시되어 있다. 이 API 계층은 친구 추가 / 제거, 사용자 프로필 업데이트 등과 같은 보조 작업을 처리한다. 이런 작업은 매우 일반적이므로 자세히 설명하지 않는다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231114204424037.png" alt=""></p>
<h4 id="Websocket-servers"><a href="#Websocket-servers" class="headerlink" title="Websocket servers"></a>Websocket servers</h4><p>친구의 위치를 거의 실시간으로 업데이트하는 stateful 서버의 클러스터다. 각 클라이언트는 이러한 서버 중 하나에 대해 하나의 영구 웹소켓 연결을 유지한다. 검색 반경 내에 있는 친구의 위치 업데이트가 있으면 이 연결을 통해 클라이언트로 업데이트가 전송된다.</p>
<p>웹소켓 서버의 또 다른 주요 역할은 “주변 친구” 기능에 대한 클라이언트 초기화를 처리하는 것이다. 이 서버는 주변의 모든 온라인 친구의 위치를 모바일 클라이언트에 추가한다.</p>
<h4 id="Redis-location-cache"><a href="#Redis-location-cache" class="headerlink" title="Redis location cache"></a>Redis location cache</h4><p>Redis는 각 활성 사용자의 가장 최근 위치 데이터를 저장하는데 사용된다. 캐시의 각 항목에는 TTL(Time to Live)가 설정되어 있다. 이 TTL이 만료되면 사용자는 더 이상 활성 상태가 아니며 위치 데이터는 캐시에서 삭제된다. 업데이트 할 때마다 TTL이 새로 고쳐진다. TTL을 지원하는 다른 KV Store도 사용 가능하다.</p>
<h4 id="User-database"><a href="#User-database" class="headerlink" title="User database"></a>User database</h4><p>사용자 데이터베이스에는 사용자 데이터와 사용자 친구 관계 데이터가 저장된다. 이를 위해 관계형 데이터베이스 또는 NoSQL 데이터베이스를 사용할 수 있다.</p>
<h4 id="Location-history-database"><a href="#Location-history-database" class="headerlink" title="Location history database"></a>Location history database</h4><p>이 데이터베이스는 사용자의 과거 위치 데이터를 저장한다. “주변 친구” 기능과는 직접적 관련은 없다.</p>
<h4 id="Redis-pub-sub-server"><a href="#Redis-pub-sub-server" class="headerlink" title="Redis pub/sub server"></a>Redis pub/sub server</h4><p>Redis pub / sub은 매우 가벼운 메세지 버스다. Redis pub / sub의 채널은 생성 비용이 매우 저렴하다. GB 단위의 메모리를 갖춘 최신 Redis 서버는 수백만 개의 채널을 저장할 수 있다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231114215144271.png" alt=""></p>
<p>이 디자인에서는 WebSocket 서버를 통해 수신된 위치 업데이트가 Redis pub / sub 서버에 있는 사용자 자신의 채널에 게시된다. 각 활성 친구에 대한 전용 WebSocket connection handelr가 채널에 가입한다. 위치 업데이트가 있을 때 Websocket handler 함수가 호출되고 각 활성 친구에 대해 함수가 거리를 다시 계산한다. 새로운 거리가 검색 반경 내에 있는 경우, 새로운 위치와 타임스탬프가 웹소켓 연결을 통해 친구의 클라이언트로 전송된다. 가벼운 채널을 가진 다른 메세지 버스도 사용할 수 있다.</p>
<p>이제 각 컴포넌트를 살펴보았으니, 시스템 관점에서 사용자의 위치가 변경되면 어떤 일이 발생하는지 살펴보자.</p>
<h3 id="Periodic-location-update"><a href="#Periodic-location-update" class="headerlink" title="Periodic location update"></a>Periodic location update</h3><p>모바일 클라이언트는 지속적인 WebSocket 연결을 통해 주기적인 위치 업데이트를 전송하며 흐름은 아래와 같다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231114215716800.png" alt=""></p>
<ol>
<li>모바일 클라이언트가 로드밸런서에 위치 업데이트를 전송한다.</li>
<li>로드밸런서는 위치 업데이트를 해당 클라이언트에 대한 웹소켓 서버의 영구 연결로 전달한다.</li>
<li>웹소켓 서버가 위치 데이터를 위치 기록 데이터베이스에 저장한다.</li>
<li>웹소켓 서버가 위치 캐시에서 새 위치를 업데이트한다. 업데이트는 TTL을 새로 고친다. 또한 웹소켓 서버는 후속 거리 계산을 위해 사용자의 웹소켓 커넥션 핸들러에 있는 변수에 새 위치를 저장한다.</li>
<li>웹소켓 서버는 새 위치를 Redis pub / sub 서버의 사용자 채널에 게시한다. 3~5단계는 병렬로 실행할 수 있다.</li>
<li>Redis pub / sub 채널에서 위치 업데이트를 수신하면 모든 구독자에게 업데이트를 브로드캐스트 한다. 이 경우 구독자는 업데이트를 보내는 사용자의 모든 온라인 친구다. 각 구독자에 대해 해당 웹소켓 커넥션 핸들러가 사용자 위치 업데이트를 수신한다.</li>
<li>메세지를 수신하면 커넥션 핸들러가 있는 웹소켓 서버는 새 위치를 보내는 사용자와 구독자 사이의 거리를 계산한다.</li>
<li>거리가 검색 반경을 초과하지 않으면 새 위치와 마지막으로 업데이트된 타임스탬프가 구독자의 클라이언트로 전송된다. 그렇지 않으면 업데이트가 삭제된다.</li>
</ol>
<p>이 흐름을 이해하는 것이 매우 중요하므로 아래에서 구체적인 예제를 통해 다시 한 번 살펴본다. 시작하기 전에 몇 가지 가정을 둔다.</p>
<ul>
<li>User 1의 친구 : user 2, user 3, user 4</li>
<li>User 5의 친구 : user 4, user 6</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231114220436398.png" alt=""></p>
<ol>
<li>User 1의 위치가 변경되면 User 1의 커넥션을 보유하고 있는 웹소켓 서버로 위치 업데이트가 전송된다.</li>
<li>위치 정보는 Redis pub / sub 서버에 있는 User 1의 채널에 게시된다.</li>
<li>Redis pub / sub 서버는 모든 구독자에게 위치 업데이트를 브로드캐스트한다. 이 경우 구독자는 웹소켓 커넥션 핸들러(User 1의 친구)다.</li>
<li>위치를 전송하는 사용자(user 1)와 구독자(user 2) 사이의 거리가 검색 반경을 초과하지 않으면 새 위치가 클라이언트(user 2)에게 전송된다.</li>
</ol>
<p>이 계산은 채널의 모든 구독자에 대해 반복된다. 평균적으로 400명의 친구가 있고 그 중 10%의 친구가 온라인 상태이며 근처에 있다고 가정하면 각 사용자의 위치 업데이트에 대해 전달해야 할 위치 업데이트는 약 40개다.</p>
<h3 id="API-design"><a href="#API-design" class="headerlink" title="API design"></a>API design</h3><p>고수준의 디자인을 완료했으므로 필요한 API들을 나열해보자.</p>
<p><strong>WebSocket</strong>: 사용자는 웹소켓 프로토콜을 통해 위치 업데이트를 주고받는다. 최소한 아래의 API들이 필요하다.</p>
<ul>
<li><p>Periodic location update</p>
<ul>
<li><p>Request : 클라이언트가 위도, 경도, timestamp를 전송</p>
</li>
<li><p>Response : Nothing</p>
</li>
</ul>
</li>
<li><p>Client receives location updates</p>
<ul>
<li>Data sent : 친구 위치 데이터 및 타임 스탬프</li>
</ul>
</li>
<li>WebSocket initialization<ul>
<li>Request : 클라이언트가 위도, 경도, 타임스탬프를 전송</li>
<li>Response : 클라이언트가 친구의 위치 데이터를 수신</li>
</ul>
</li>
<li>Subscribe to a new friend<ul>
<li>Request : 웹소켓 서버가 친구 ID를 전송</li>
<li>Response : 친구의 최신 위도, 경도 및 타임스탬프</li>
</ul>
</li>
<li>Unsubscribe a friend<ul>
<li>Request : 웹소켓 서버가 친구 ID를 전송</li>
<li>Response : Nothing</li>
</ul>
</li>
<li>HTTP requests : API 서버가 친구 추가 / 제거, 사용자 프로필 업데이트 등의 작업을 처리한다. 이런 작업은 매우 일반적이므로 여기서는 자세히 설명하지 않는다.</li>
</ul>
<h3 id="Data-model"><a href="#Data-model" class="headerlink" title="Data model"></a>Data model</h3><p>논의해야 할 또 다른 중요한 요소는 데이터 모델이다. 고수준 디자인에서 이미 사용자 DB에 대해 이야기했으므로 여기서는 위치 캐시 및 위치 기록 데이터베이스에 대해 집중적으로 살펴본다.</p>
<h4 id="Location-cache"><a href="#Location-cache" class="headerlink" title="Location cache"></a>Location cache</h4><p>위치 캐시는 주변 친구 기능을 켠 모든 활성 사용자의 최신 위치를 저장한다. 이 캐시는 Redis를 사용하며 캐시의 KV는 아래 나와있다.</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left"><strong>key</strong></th>
<th style="text-align:left"><strong>value</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">user_id</td>
<td style="text-align:left">{latitude, longitude, timestamp}</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Why don’t we use a database to store location data?</strong></p>
<p>주변 친구 기능은 사용자의 현재 위치에만 관심을 갖는다. 따라서 사용자당 하나의 위치만 저장하면 된다. Redis는 초고속 읽기 및 쓰기 작업을 제공하므로 탁월한 선택이다. 더 이상 활동하지 않는 사용자를 캐시에서 자동 제거 할 때 사용하는 TTL을 지원한다. 현재 위치를 영구적으로 저장할 필요가 없다. Redis 인스턴스가 다운되면 이를 빈 새 인스턴스로 교체하고 새로운 위치 업데이트가 들어올 때 캐시를 채울 수 있다. 새 캐시가 따뜻해지는 동안 활성 사용자는 한 두번의 업데이트 주기 동안 친구의 위치 업데이트를 놓칠 수 있다. 이는 허용 가능한 절충안이다. 후반에는 캐시가 교체될 때 사용자에게 미치는 영향을 줄이는 방법에 대해 설명한다.</p>
<h4 id="Location-history-database-1"><a href="#Location-history-database-1" class="headerlink" title="Location history database"></a>Location history database</h4><p>위치 기록 데이터베이스는 사용자의 과거 위치 데이터를 저장하며 스키마는 아래와 같다.</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">user_id</th>
<th style="text-align:left">latitude</th>
<th style="text-align:left">longitude</th>
<th style="text-align:left">timestamp</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
</tr>
</tbody>
</table>
</div>
<p>대용량 쓰기 워크로드를 잘 처리하고 수평적으로 확장할 수 있는 데이터베이스가 필요하다. Cassandra가 좋은 후보다. 관계형 데이터베이스를 사용할 수도 있다. 하지만 관계형 데이터베이스를 사용하면 기록 데이터가 단일 인스턴스에 맞지 않으므로 데이터를 샤딩해야 한다. 가장 기본적인 접근 방식은 사용자 ID 별로 샤딩하는 것이다. 이 샤딩 방식은 모든 샤드에 부하가 고르게 분산되도록 보장하며, 운영적으로도 유지 관리가 쉽다.</p>
<h2 id="Step-3-Design-Deep-Dive"><a href="#Step-3-Design-Deep-Dive" class="headerlink" title="Step 3 - Design Deep Dive"></a>Step 3 - Design Deep Dive</h2><p>이전 섹션에서 만든 고수준 디자인은 대부분의 경우 작동하지만 규모에 따라 문제가 발생할 수 있다. 이 섹션에서는 규모를 늘리면서 병목 현상을 발견하고, 그 과정에서 병목 현상을 제거할 수 있는 솔루션을 함께 모색한다.</p>
<h3 id="How-well-does-each-component-scale"><a href="#How-well-does-each-component-scale" class="headerlink" title="How well does each component scale?"></a>How well does each component scale?</h3><h4 id="API-servers"><a href="#API-servers" class="headerlink" title="API servers"></a>API servers</h4><p>RESTful API 계층을 확장하는 방법은 잘 알려져 있다. 이런 서버는 stateless 서버이며 CPU usage, load, I/O에 따라 클러스터를 자동 확장하는 방법이 있다. </p>
<h4 id="WebSocket-servers"><a href="#WebSocket-servers" class="headerlink" title="WebSocket servers"></a>WebSocket servers</h4><p>웹소켓 클러스터의 경우 사용량에 따라 자동 확장하는 것은 어렵지 않다. 그러나 웹소켓 서버는 stateful 이므로 기존 노드를 제거할 때는 주의해야 한다. 노드를 제거하기 전에 기존의 모든 연결이 끊어져야 한다. 이를 위해 로드 밸런서에서 노드를 “draining”으로 표시해 배수중인 서버로 새 웹소켓 연결이 라우팅되지 않도록 할 수 있다. 기존 연결이 모두 종료되면 서버가 제거된다.</p>
<p>웹소켓 서버에서 애플리케이션 소프트웨어의 새 버전을 릴리스할 때도 동일한 수준의 주의가 필요하다.</p>
<p>Stateful 서버의 효과적인 자동 확장은 좋은 로드 밸런서가 해야 할 일이라는 점에 주목할 필요가 있다. 대부분의 클라우드 로드 밸런서는 이 작업을 매우 잘 처리한다.</p>
<p><strong>Client Initialization</strong></p>
<p>시작 시 모바일 클라이언트는 웹소켓 서버 인스턴스 중 하나와 영구적인 웹소켓 연결을 설정한다. 각 연결은 오래 지속된다. 대부분의 최신 언어는 상당히 적은 메모리 사용량으로 많은 long-running 커넥션을 유지할 수 있다.</p>
<p>웹소켓 연결이 초기화되면 클라이언트는 사용자의 초기 위치를 전송하고 서버는 웹소켓 커넥션 핸들러에서 다음 작업을 수행한다.</p>
<ol>
<li>위치 캐시에서 사용자의 위치를 업데이트 한다.</li>
<li>후속 계산을 위해 커넥션 핸들러의 변수에 위치를 저장한다.</li>
<li>사용자 데이터베이스에서 사용자의 모든 친구를 로드한다.</li>
<li>모든 친구의 위치를 가져오기 위해 위치 캐시에 일괄 요청을 한다. 비활성 시간 제한 기간과 일치하도록 위치 캐시의 각 항목에 TTL을 설정했기 떄문에 친구가 비활성 상태인 경우 위치 캐시에 해당 친구의 위치가 저장되지 않는다.</li>
<li>위치 캐시가 반환하는 각 위치에 대해 서버는 해당 위치에서 사용자와 친구 사이의 거리를 계산한다. 거리가 검색 반경 내에 있으면 친구의 프로필, 위치 및 마지막으로 업데이트된 타임스탬프가 웹소켓 커넥션을 통해 클라이언트에 반환된다.</li>
<li>각 친구에 대해 서버는 Redis pub / sub 서버에 있는 친구의 채널에 가입한다. 새 채널을 만드는 비용이 저렴하므로 사용자는 활성 및 비활성 친구를 모두 구독한다. 비활성 친구는 Redis pub / sub 서버에서 소량의 메모리를 차지하지만 온라인 상태가 될 때 까지 (업데이트를 게시하지 않으므로) CPU나 I/O를 사용하지 않는다.</li>
<li>이 친구는 사용자의 현재 위치를 Redis pub / sub 서버의 사용자 채널로 보낸다.</li>
</ol>
<h4 id="User-database-1"><a href="#User-database-1" class="headerlink" title="User database"></a>User database</h4><p>사용자 데이터베이스에는 사용자 프로필(ID, 이름, 프로필 url 등)과 친구 관계라는 두 가지 데이터 세트가 저장된다. 설계 규모에서 이런 데이터 세트는 단일 관계형 데이터베이스 인스턴스에 맞지 않을 가능성이 높다. 좋은 소식은 사용자 ID를 기반으로 샤딩해 데이터를 수평적으로 확장할 수 있다는 것이다. 관계형 데이터베이스 샤딩은 매우 일반적인 기술이다.</p>
<p>참고로, 우리가 설계하고 있는 규모에서는 사용자 및 친구 관계 데이터 세트가 전담 팀에 의해 관리되고 내부 API를 통해 제공될 가능성이 높다. 이 시나리오에서는 웹소켓 서버가 사용자 및 친구 관계 관련 데이터를 가져오기 위해 데이터베이스를 직접 쿼리하는 대신 내부 API를 사용한다. API를 통해 액세스하든 직접  데이터베이스를 쿼리하든 기능이나 성능 측면에서 큰 차이는 없다.</p>
<h4 id="Location-cache-1"><a href="#Location-cache-1" class="headerlink" title="Location cache"></a>Location cache</h4><p>모든 활성 사용자의 가장 최근 위치를 캐시하기 위해 Redis를 선택했다. 앞서 언급했듯이 각 키에 TTL도 설정했다. TTL은 위치가 업데이트될 때마다 갱신된다. 이렇게 하면 사용되는 최대 메모리 양에 제한이 생긴다. 활성 사용자가 최대 10M 명이고 각 위치가 100byte를 넘지 않는다면 많은 GB의 메모리를 갖춘 최신 Redis 서버 한 대로 모든 사용자의 위치 정보를 쉽게 보관할 수 있다.</p>
<p>그러나 활성 사용자 천 만명이 대략 30초 마다 업데이트하는 경우, Redis 서버는 초당 334,000건의 업데이트를 처리해야 한다. 이는 최신 하이엔드 서버라고 해도 너무 높은 수치이다. 다행이도 이 캐시 데이터는 쉽게 샤딩할 수 있다. 각 사용자의 위치 데이터는 독립적이며, 사용자 ID를 기반으로 위치 데이터를 샤딩해 여러 Redis 서버에 부하를 균등하게 분산할 수 있다.</p>
<p>가용성을 개선하기 위해 각 샤드의 위치 데이터를 standby 노드에 복제할 수 있다. 주 노드가 다운되면 standby 노드가 신속하게 승격되어 다운타임을 최소화할 수 있다.</p>
<h4 id="Redis-pub-sub-server-1"><a href="#Redis-pub-sub-server-1" class="headerlink" title="Redis pub/sub server"></a>Redis pub/sub server</h4><p>pub / sub 서버는 한 사용자로부터 모든 온라인 친구에게 메세지(위치 업데이트)를 전달하는 라우팅 계층으로 사용된다. 앞서 언급했듯이 새 채널을 생성하는 데 매우 가볍기 때문에 Redis pub / sub을 선택했다. 누군가가 채널을 구독하면 새 채널이 생성된다. 구독자가 없는 채널에 메세지가 게시되면 메세지가 삭제되므로 서버에 부하가 거의 걸리지 않는다. 채널이 생성되면 Redis는 소량의 메모리를 사용해 해시 테이블과 링크드 리스트를 유지 관리해 구독자를 추적한다. 사용자가 오프라인 상태일 때 채널에 대한 업데이트가 없으면 채널이 생성된 후 CPU 사이클이 사용되지 않는다. 다음과 같은 방식으로 이 점을 설계에 활용한다.</p>
<ul>
<li><p>주변 친구 기능을 사용하는 모든 사용자에게 고유한 채널을 할당한다. 사용자는 앱 초기화 시 친구가 온라인 상태인지 여부에 관계 없이 각 친구의 채널을 구독하게 된다. 이렇게 하면 백엔드에서 친구가 활성화될 때 친구의 채널을 구독하거나 친구가 비활성 상태일 때 구독 취소를 처리할 필요가 없으므로 설계가 간단해진다.</p>
</li>
<li><p>단점은 디자인이 더 많은 메모리를 사용한다는 것이다. 나중에 살펴보겠지만 메모리 사용량이 병목 현상이 되지는 않을 것이다. 이 경우에는 더 많은 메모리 사용량을 더 간단한 아키텍처와 교환할 가치가 있다.</p>
</li>
</ul>
<p><strong>How many Redis pub/sub servers do we need?</strong></p>
<p>메모리와 CPU 사용량을 계산해보자.</p>
<p><strong>Memory usage</strong></p>
<p>주변 친구 기능을 사용하는 각 사용자에게 채널이 할당되었다고 가정하면 1억 개의 채널(10억 <em> 10%)이 필요하다. 평균적으로 한 사용자가 이 기능을 사용하는 활성 친구가 100명이고(근처에 있거나 그렇지 않은 친구 포함), 각 구독자를 추적하는데 내부 해시 테이블과 링크드리스트 목록에 약 20바이트의 포인터가 필요하다고 가정하면, 모든 채널을 보유하기 위해선 약 200GB(1억 </em> 20byte * 100 friends / 10^9 = 200GB)가 필요하다. 메모리가 100GB인 최신 서버의 경우, 모든 채널을 보유하려면 약 2개의 Redis pub / sub 서버가 필요하다.</p>
<p><strong>CPU usage</strong></p>
<p>앞서 계산한 것처럼, pub / sub 서버는 초당 약 1,400만 개의 업데이트를 구독자에게 푸시한다. 실제 벤치마킹 없이 최신 Redis 서버가 초당 얼마나 많은 메세지를 푸시할 수 있는지 정확하게 추정하기는 쉽지 않지만, 단일 Redis 서버로는 이 부하를 처리할 수 없을 것이라고 가정하는 것이 안전하다. 보수적인 수치를 선택해 gigabit 네트워크를 갖춘 최신 서버가 초당 약 100,000건의 구독자 푸시를 처리할 수 있다고 가정해 보자. 위치 업데이트 메세지가 얼마나 작은지 고려할 때 이 수치는 보수적일 가능성이 높다. 이 보수적인 추정치를 사용하면 1400만 / 100,000 = 140개의 Redis 서버에 부하를 분산해야 한다. 하지만 보수적인 수치이기 때문에 실제 서버 수는 더 적을 수 있다.</p>
<p>계산을 통해 아래와 같은 결론을 도출했다.</p>
<ul>
<li>Redis pub / sub 서버의 병목 현상은 메모리 사용량이 아니라 CPU 사용량이다.</li>
<li>우리의 규모를 지원하려면 분산된 Redis pub / sub 클러스터가 필요하다.</li>
</ul>
<h5 id="Distributed-Redis-pub-sub-server-cluster"><a href="#Distributed-Redis-pub-sub-server-cluster" class="headerlink" title="Distributed Redis pub/sub server cluster"></a>Distributed Redis pub/sub server cluster</h5><p>수백 대의 Redis 서버에 채널을 배포하려면 어떻게 해야 할까? 좋은 소식은 채널이 서로 독립적이라는 것이다. 따라서 publisher의 사용자 ID를 기반으로 샤딩을 통해 여러 pub / sub 서버에 채널을 비교적 쉽게 분산할 수 있다. 하지만 실제로는 100개의 pub / sub 서버가 있는 경우 서버가 수시로 다운될 수 밖에 없기 때문에 운영상 어느 정도로 관리가 가능하도록 샤딩을 수행하는 방법에 대해 좀 더 자세히 살펴볼 필요가 있다.</p>
<p>여기서는 서비스 검색 구성 요소를 설계에 도입한다. 사용 가능한 서비스 검색 패키지는 여러 가지가 있으며, 그 중 에서도 etcd와 Zookeeper가 가장 널리 사용된다. 서비스 검색 컴포넌트에 필요한 것은 매우 기본적인 것이다. </p>
<ul>
<li>서비스 검색 구성 요소에 서버 목록을 보관하는 기능과 이를 업데이트할 수 있는 간단한 UI 또는 API다. 기본적으로 서비스 검색은 설정 데이터를 보관하기 위한 작은 KV Store다. 예를 들어, 해시 링의 키와 값은 아래와 같이 보일 수 있다.</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Key: /config/pub_sub_ring</span><br><span class="line">Value: [ “p_1”, “p_2”, “p_3”, “p_4”]</span><br></pre></td></tr></table></figure>
<ul>
<li>클라이언트(웹소켓 서버)가 값(Redis pub / sub 서버)에 대한 모든 업데이트를 구독할 수 있는 기능</li>
</ul>
<p>위에서 언급한 “Key” 아래에 서비스 검색 구성 요소에 모든 활성 Redis pub / sub 서버의 해시 링을 저장한다. 해시 링은 Redis pub / sub 서버의 게시자 및 구독자가 각 채널에 대해 통신할 pub / sub 서버를 결정하는 데 사용된다. </p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231114225124151.png" alt=""></p>
<p>아래는 웹소켓 서버가 사용자의 채널에 위치 업데이트를 게시할 때 어떤 일이 발생하는지 보여준다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231114225202344.png" alt=""></p>
<ol>
<li>웹소켓 서버는 해시 링을 참조해 사용할 Redis pub / sub 서버를 결정한다. 원본은 서비스 검색에 저장되지만, 효율성을 위해 해시 링의 복사본을 각 웹소켓 서버에 캐시할 수 있다. 웹소켓 서버는 해시 링의 모든 업데이트를 구독해 로컬 인메모리 사본을 최신 상태로 유지한다.</li>
<li>웹소켓 서버는 위치 업데이트를 해당 Redis pub / sub 서버의 사용자 채널에 게시한다.</li>
</ol>
<p>위치 업데이트를 위한 채널 구독도 동일한 메커니즘을 사용한다.</p>
<h5 id="Scaling-considerations-for-Redis-pub-sub-servers"><a href="#Scaling-considerations-for-Redis-pub-sub-servers" class="headerlink" title="Scaling considerations for Redis pub/sub servers"></a>Scaling considerations for Redis pub/sub servers</h5><p>Redis pub / sub 서버 클러스터를 어떻게 확장해야 할까? 트래픽 패턴에 따라 매일 확장 및 축소 해야 할까? 이는 위험이 낮고 비용을 절약할 수 있기 때문에 stateless 서버에서 매우 일반적인 관행이다. 이런 질문에 답하기 위해 Redis pub / sub 서버 클러스터의 몇 가지 속성을 살펴보자.</p>
<ol>
<li>pub / sub 채널에서 전송된 메세지는 메모리나 디스크에 지속되지 않는다. 채널의 모든 구독자에게 전송된 후 즉시 제거된다. 구독자가 없는 경우에는 메시지가 그냥 삭제된다. 이런 의미에서 pub / sub 채널을 통과하는 데이터는 상태가 없다.</li>
<li>그러나 실제로 채널의 pub / sub 서버에는 상태가 저장되어 있다. 특히 각 채널의 구독자 목록은 pub / sub 서버에서 추적하는 상태의 핵심 부분이다. 채널의 pub / sub 서버가 교체되거나 해시 링에서 새 서버가 추가되거나 기존 서버가 제거되는 등 채널이 이동되면 이동된 채널의 모든 구독자가 이 사실을 알고 있어야 이전 서버의 채널 구독을 취소하고 새 서버의 교체된 채널에 다시 구독할 수 있다. 이런 의미에서 pub / sub 서버는 stateful 서버이며 서비스 중단을 최소화하기 위해 서버의 모든 가입자와의 조정을 조율해야 한다.</li>
</ol>
<p>이런 이유로 스토리지 클러스터를 처리하는 방식과 유사하게 Redis pub / sub 클러스터를 stateful 클러스터 처럼 취급해야 한다. Stateful 클러스터를 사용하면 규모를 확장하거나 축소할 때 약간의 운영 오버헤드와 위험이 따르므로 신중한 계획을 가지고 수행해야 한다. 클러스터는 일반적으로 오버프로비저닝 되어 클러스터의 불필요한 크기 조정을 피할 수 있는 여유 공간을 확보한 상태에서 일일 최대 트래픽을 처리할 수 있도록 한다.</p>
<p>불가피하게 규모를 확장해야 하는 경우에는 아래와 같은 잠재적인 문제에 유의해야 한다.</p>
<ul>
<li>클러스터의 크기를 조정하면 많은 채널이 해시 링의 다른 서버로 이동하게 된다. 서비스 검색 컴포넌트가 해시 링 업데이트를 모든 웹소켓 서버에 알리면 수많은 재구독 요청이 발생할 수 있다.</li>
<li>이런 대량 재가입 이벤트 중에 클라이언트가 일부 위치 업데이트를 놓칠 수 있다. 간혹 누락되는 것은 설계상 허용되나 누락을 최소화 해야한다.</li>
<li>잠재적인 중단이 발생할 수 있으므로 크기 조정은 하루 중 사용량이 가장 적은 시간에 수행해야 한다.</li>
</ul>
<p>크기 조정은 아래와 같이 이루어진다.</p>
<ul>
<li>새 링 크기를 결정하고, 확장할 경우 새 서버를 충분히 프로비저닝 한다.</li>
<li>해시 링의 키를 새 콘텐츠로 업데이트 한다.</li>
<li>대시보드를 모니터링 한다. 웹소켓 클러스터의 CPU 사용량이 어느 정도 급증해야 한다.</li>
</ul>
<p>위의 해시 링을 사용해 2개의 새 노드 (p_5, p_6)를 추가하면 해시링은 아래와 같이 업데이트 된다.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Old: [ “p_1”, “p_2”, “p_3”, “p_4”]</span><br><span class="line"></span><br><span class="line">New: [ “p_1”, “p_2”, “p_3”, “p_4”, “p_5”, “p_6”]</span><br></pre></td></tr></table></figure>
<h5 id="Operational-considerations-for-Redis-pub-sub-servers"><a href="#Operational-considerations-for-Redis-pub-sub-servers" class="headerlink" title="Operational considerations for Redis pub/sub servers"></a>Operational considerations for Redis pub/sub servers</h5><p>기존 Redis pub / sub 서버를 교체할 때의 운영 위험은 훨씬 더 낮다. 많은 수의 채널을 이동시키지 않는다. 교체되는 서버의 채널만 처리하면 된다. 서버는 필연적으로 다운되고 정기적으로 교체해야 하기 때문에 이 점이 좋다.</p>
<p>pub / sub 서버가 다운되면 모니터링 소프트웨어가 대기 중인 운영자에게 경고를 보내야 한다. 모니터링 소프트웨어가 정확히 어떻게 pub / sub 상태를 모니터링 하는지는 이 장의 범위를 넘어서기에 다루지 않는다. 대기 중 운영자는 서비스 검색에서 해시 링 키를 업데이트해 데드 노드를 새로운 대기 노드로 교체한다. 웹소켓 서버는 업데이트에 대한 알림을 받고 각 서버는 연결 처리기에 새 pub / sub 서버의 채널에 다시 가입하도록 알린다. 각 웹소켓 핸들러는 구독한 모든 채널의 목록을 보관하고 서버로부터 알림을 받으면 해시 링과 비교해 각 채널을 확인해 새 서버에서 채널을 다시 구독해야 하는지 여부를 결정한다.</p>
<p>이 해시 링을 사용해 p_1이 다운된 경우 이를 p1_new로 교체하면 해시 링은 아래와 같이 업데이트 된다.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Old: [ “p_1”, “p_2”, “p_3”, “p_4”]</span><br><span class="line"></span><br><span class="line">New: [ “p_1_new”, “p_2”, “p_3”, “p_4”]</span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231114231306268.png" alt=""></p>
<h3 id="Adding-removing-friends"><a href="#Adding-removing-friends" class="headerlink" title="Adding/removing friends"></a>Adding/removing friends</h3><p>사용자가 친구를 추가하거나 삭제할 때 클라이언트는 어떻게 해야 할까? 새 친구가 추가되면 서버의 클라이언트 웹소켓 커넥션 핸들러에 알림을 보내야 새 친구의 pub / sub 채널에 가입할 수 있다.</p>
<p>“주변 친구” 기능은 더 큰 앱의 에코시스템 내에 있으므로 새 친구가 추가될 때 마다 모바일 클라이언트에 콜백을 등록할 수 있다고 가정할 수 있다. 콜백이 호출되면 새 친구의 pub / sub 채널에 가입하라는 메세지를 웹소켓 서버로 보낸다. 또한 웹소켓 서버는 새 친구가 활성화되어 있는 경우 새 친구의 최신 위치와 타임스탬프가 포함된 메세지를 반환한다.</p>
<p>마찬가지로 클라이언트는 친구가 제거될 때마다 애플리케이션에 콜백을 등록할 수 있다. 콜백은 웹소켓 서버로 메세지를 전송해 친구의 pub / sub 채널 구독을 취소한다.</p>
<p>이 구독 / 구독 취소 콜백은 친구가 위치 업데이트를 opt-in하거나 opt-out할 때마다 사용할 수도 있다.</p>
<h3 id="Users-with-many-friends"><a href="#Users-with-many-friends" class="headerlink" title="Users with many friends"></a>Users with many friends</h3><p>친구 수가 많은 사용자가 설계상 성능 핫스팟을 유발할 수 있는지에 대해 논의해 볼 필요가 있다. 여기서는 친구 수에 엄격한 상한선이 있다고 가정한다. 친구 관계는 양방향이다. 유명인이 수백만 명의 팔로워를 보유할 수 있는 팔로워 모델에 대해 이야기하는 것이 아니다.</p>
<p>수천 명의 친구가 있는 시나리오에서 pub / sub 구독자는 클러스터의 여러 웹소켓 서버에 흩어져 있을 것이다. 업데이트 부하가 분산되어 핫스팟이 발생할 가능성은 거의 없다.</p>
<p>사용자는 채널이 있는 pub / sub 서버에 조금 더 많은 부하가 걸린다. 100개가 넘는 pub / sub 서버가 있기 때문에 이러한 “고래” 사용자는 pub / sub t서버에 분산될 것이며 증가된 부하가 어느 한 서버를 압도하진 않을 것이다.</p>
<h3 id="Nearby-random-person"><a href="#Nearby-random-person" class="headerlink" title="Nearby random person"></a>Nearby random person</h3><p>이 섹션은 초기 기능 요구 사항에 포함되어 있지 않으므로 추가 크레딧이라고 할 수 있다. 면접관이 위치 공유에 동의한 임의의 사람들을 표시하도록 디자인을 업데이트하고 싶다면 어떻게 해야할까?</p>
<p>디자인을 활용하면서 이를 수행하는 한 가지 방법은 geohash를 기준으로 pub / sub 채널 pool을 추가하는 것이다. 아래와 같이 한 지역을 4개의 geohash 그리드로 나누고 각 그리드에 대해 채널을 생성한다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231114231920920.png" alt=""></p>
<p>그리드 내의 모든 사용자는 동일한 채널을 구독한다. 그리드 9q8znd를 예로 들어보자.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231114231956472.png" alt=""></p>
<ol>
<li>사용자 2가 위치를 업데이트하면 웹소켓 커넥션 핸들러가 사용자의 geohash ID를 계산해 해당 geohash의 채널로 위치를 보낸다.</li>
<li>발신자를 제외한 채널에 가입한 근처의 모든 사람이 위치 업데이트 메세지를 받게 된다.</li>
</ol>
<p>geohash 그리드의 경계에 가까운 사람들을 처리하기 위해 모든 클라이언트는 사용자가 있는 geohash와 주변 8개의 geohash 그리드를 구독할 수 있다. 9개의 geohash 그리드가 모두 강조 표시된 예는 아래에 나와있다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231114232121088.png" alt=""></p>
<h3 id="Alternative-to-Redis-pub-sub"><a href="#Alternative-to-Redis-pub-sub" class="headerlink" title="Alternative to Redis pub/sub"></a>Alternative to Redis pub/sub</h3><p>라우팅 레이어로 Redis pub / sub을 사용하는 것 외에 좋은 대안이 있을까? 대답은 “그렇다”다. Erlang은 이 특정 문제에 대한 훌륭한 솔루션이다. 위에서 제안한 Redis pub / sub 보다 Erlang이 더 나은 솔루션이라고 주장할 수 있다. 그러나 Erlang은 상당히 틈새 시장이며 좋은 Erlang 프로그래머를 고용하는 것은 어렵다. 하지만 팀에 Erlang 전문 지식인이 있으면 이는 훌륭한 옵션이다.</p>
<p>그렇다면 왜 Erlang 일까? Erlang은 고도로 분산되고 동시 실행되는 애플리케이션을 위해 구축된 일반 프로그래밍 언어이자 런타임 환경이다. 여기서 말하는 Erlang은 Erlang 에코시스템 자체를 의미한다. 여기에는 언어 구성요소(Erlang 또는 Elixir)와 런타임 환경 및 라이브러리(BEAM이라는 Erlang 가상 머신과 OTP라는 Erlang 런타임 라이브러리)가 포함된다.</p>
<p>Erlang의 강점은 경량 프로세스에 있다. Erlang 프로세스는 BEAM 가상 머신에서 실행되는 엔티티다. Linux 프로세스보다 생성 비용이 몇 배나 저렴하다. 최소한 Erlang 프로세스는 약 300바이트가 소요되며, 최신 서버 한 대에 이런 프로세스를 수백만 개나 보유할 수 있다. Erlang 프로세스에서 수행해야 할 작업이 없으면 CPU 사이클을 전혀 사용하지 않고 그냥 앉아 있을 뿐이다. 다시 말해 천만 명의 활성 사용자를 각각 개별 Erlang 프로세스로 모델링하는 것은 매우 저렴한 비용으로 설계할 수 있다.</p>
<p>또한 Erlang은 여러 대의 Erlang 서버에 배포하기가 매우 쉽다. 운영 오버헤드가 매우 낮고, 라이브 프로덕션 문제를 안전하게 디버깅할 수 있도록 지원하는 훌륭한 도구가 있다. 배포 도구도 매우 강력하다.</p>
<p>디자인에 Erlang을 어떻게 사용해야 할까? 우리는 Erlang으로 웹소켓 서비스를 구현하고 전체 Redis pub / sub 클러스터를 분산된 Erlang 애플리케이션으로 대체할 것이다. 이 애플리케이션에서 각 사용자는 Erlang 프로세스로 모델링 된다. 사용자 프로세스는 클라이언트에 의해 사용자 위치가 업데이트될 때 웹소켓 서버로부터 업데이트를 수신한다. 또한 사용자 프로세스는 사용자 친구의 Erlang 프로세스에서 업데이트를 구독한다. 구독은 Erlang/OTP에서 기본 제공되며 쉽게 빌드할 수 있다. 이렇게 하면 한 사용자로부터 많은 친구에게 위치 업데이트를 효율적으로 라우팅하는 연결 메시가 형성된다.</p>
<h2 id="Step-4-Wrap-Up"><a href="#Step-4-Wrap-Up" class="headerlink" title="Step 4 - Wrap Up"></a>Step 4 - Wrap Up</h2><p>이 포스트에서는 주변 친구 기능을 지원하는 디자인을 소개했다. 개념적으로 우리는 한 사용자의 위치 업데이트를 친구에게 효율적으로 전달할 수 있는 시스템을 설계하고자 했다. 핵심 구성 요소는 다음과 같다.</p>
<ul>
<li>WebSocket : 클라이언트와 서버간의 실시간 통신</li>
<li>Redis : 위치 데이터의 빠른 읽기 및 쓰기</li>
<li>Redis pub / sub : 한 사용자의 위치 업데이트를 모든 온라인 친구에게 전달하는 라우팅 계층</li>
</ul>
<p>먼저 낮은 규모의 고수준 설계를 진행한 뒤, 규모가 커짐에 따라 발생하는 문제에 대해 논의했다. 다음과 같이 확장하는 방법을 살펴봤다.</p>
<ul>
<li>Restful API servers</li>
<li>WebSocket servers</li>
<li>Data layer</li>
<li>Redis pub/sub servers</li>
<li>Alternative to Redis pub/sub</li>
</ul>
<p>마지막으로 사용자가 많은 친구를 보유하고 있을 때 발생할 수 있는 병목현상에 대해 논의하고 “주변 무작위 사람” 기능에 대한 설계를 제안했다.</p>
<h2 id="Chapter-Summary"><a href="#Chapter-Summary" class="headerlink" title="Chapter Summary"></a>Chapter Summary</h2><p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20231114233053804.png" alt=""></p>
<!-- flag of hidden posts --></div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Song Hayoung</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://songhayoung.github.io/2023/11/14/System%20Design/ByteByteGo/book/nearby-friends/">https://songhayoung.github.io/2023/11/14/System%20Design/ByteByteGo/book/nearby-friends/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/System-Design/">System Design</a></div><nav id="pagination"></nav><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: '3604b61642355579f55e',
  clientSecret: 'f552120f18ac5aee3f6297e05e97d94c0a25cd4b',
  repo: 'SongHayoung.github.io',
  owner: 'SongHayoung',
  admin: 'SongHayoung',
  id: md5(decodeURI(location.pathname)),
  language: 'en'
})
gitalk.render('gitalk-container')</script></div></div><footer class="footer-bg" style="background-image: url(https://xxxx.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2020 - 2025 By Song Hayoung</div><div class="framework-info"><span>Driven - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">Learning how to walk slowly to not miss important things</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.7.0"></script><script src="/js/fancybox.js?version=1.7.0"></script><script src="/js/sidebar.js?version=1.7.0"></script><script src="/js/copy.js?version=1.7.0"></script><script src="/js/fireworks.js?version=1.7.0"></script><script src="/js/transition.js?version=1.7.0"></script><script src="/js/scroll.js?version=1.7.0"></script><script src="/js/head.js?version=1.7.0"></script><script src="/js/search/algolia.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="algolia-search"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>