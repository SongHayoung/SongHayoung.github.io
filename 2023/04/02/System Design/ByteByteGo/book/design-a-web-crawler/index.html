<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="[System Design] Design A Web Crawler"><meta name="keywords" content="System Design"><meta name="author" content="Song Hayoung"><meta name="copyright" content="Song Hayoung"><title>[System Design] Design A Web Crawler | SUMFIのBlog</title><meta name="robots" content="noindex"><link rel="shortcut icon" href="/songcon.ico"><link rel="stylesheet" href="/css/index.css?version=1.7.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.7.0"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css?version=1.7.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.js" defer></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><link rel="dns-prefetch" href="https://www.google-analytics.com"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-169368422-1', 'auto');
ga('send', 'pageview');</script><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"7LZ6OJ4D6C","apiKey":"9a84e13f74ea78c3fd54512c10139c56","indexName":"git blog","hits":{"per_page":10},"languages":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}.","hits_stats":"${hits} results found in ${time} ms"}},
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/rss2.xml" title="SUMFIのBlog" type="application/rss+xml">
</head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Design-A-Web-Crawler"><span class="toc-number">1.</span> <span class="toc-text">Design A Web Crawler</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Step-1-Understand-the-problem-and-establish-design-scope"><span class="toc-number">2.</span> <span class="toc-text">Step 1 - Understand the problem and establish design scope</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Back-of-the-envelope-estimation"><span class="toc-number">2.1.</span> <span class="toc-text">Back of the envelope estimation</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Step-2-Propose-high-level-design-and-get-buy-in"><span class="toc-number">3.</span> <span class="toc-text">Step 2 - Propose high-level design and get buy-in</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Step-3-Design-deep-dive"><span class="toc-number">4.</span> <span class="toc-text">Step 3 - Design deep dive</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#DFS-vs-BFS"><span class="toc-number">4.1.</span> <span class="toc-text">DFS vs BFS</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#URL-frontier"><span class="toc-number">4.2.</span> <span class="toc-text">URL frontier</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Politeness"><span class="toc-number">4.2.1.</span> <span class="toc-text">Politeness</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Priority"><span class="toc-number">4.2.2.</span> <span class="toc-text">Priority</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Freshness"><span class="toc-number">4.2.3.</span> <span class="toc-text">Freshness</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Storage-for-URL-Frontier"><span class="toc-number">4.2.4.</span> <span class="toc-text">Storage for URL Frontier</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HTML-Downloader"><span class="toc-number">4.3.</span> <span class="toc-text">HTML Downloader</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Robots-txt"><span class="toc-number">4.3.0.1.</span> <span class="toc-text">Robots.txt</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Performance-optimization"><span class="toc-number">4.3.0.2.</span> <span class="toc-text">Performance optimization</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Robustness"><span class="toc-number">4.4.</span> <span class="toc-text">Robustness</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Extensibility"><span class="toc-number">4.5.</span> <span class="toc-text">Extensibility</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Detect-and-avoid-problematic-content"><span class="toc-number">4.6.</span> <span class="toc-text">Detect and avoid problematic content</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Step-4-Wrap-up"><span class="toc-number">5.</span> <span class="toc-text">Step 4 - Wrap up</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="https://avatars3.githubusercontent.com/u/37806785?s=460&amp;u=8c68d685faf7c5280cfbd736a6b1730b55fb4203&amp;v=4"></div><div class="author-info__name text-center">Song Hayoung</div><div class="author-info__description text-center"></div><div class="follow-button"><a target="_blank" rel="noopener" href="https://www.linkedin.com/in/hayoung-song-9523b61bb/">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">10798</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">193</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">61</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">VISITED</div><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">Seoul Korea</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">Jeju Korea</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">British Columbia Canada</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">Boracay Philippines</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">三重　日本</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">大阪　日本</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">名古屋　日本</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">静岡　日本</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">札幌　日本</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">京都　日本</a><a class="author-info-links__name text-center" href="https://songhayoung.github.io/">Bangkok Thailand</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://xxxx.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">SUMFIのBlog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a><a class="site-page" href="/about">About</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> Search</span></a></span></div><div id="post-info"><div id="post-title">[System Design] Design A Web Crawler</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-04-02</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/System-Design/">System Design</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/System-Design/System-Design-Interview/">System Design Interview</a><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">1.5k</span><span class="post-meta__separator">|</span><span>Reading time: 9 min</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h2 id="Design-A-Web-Crawler"><a href="#Design-A-Web-Crawler" class="headerlink" title="Design A Web Crawler"></a>Design A Web Crawler</h2><span id="more"></span>
<p>웹 크롤러는 몇개의 웹 페이지를 수집하는 것으로 시작한 다음 해당 페이지의 링크를 따라 새로운 콘텐츠를 수집한다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20230402232215846.png" alt="image-20230402232215846"></p>
<p>크롤러는 다양한 용도로 사용된다.</p>
<ul>
<li>검색 엔진 인덱싱 : 가장 일반적인 사용사례. 웹 페이지를 수집해 검색 엔진의 로컬 인덱스를 생성</li>
<li>웹 아카이빙 : 웹에서 정보를 수집해 향후 사용을 위해 데이터를 보존하는 프로세스</li>
<li>웹 마이닝 : 인터넷에서 주주 회의, 연례 보고서 등과 같이 유용한 지식을 발견하는데 사용</li>
<li>웹 모니터링 : 인터넷을 통한 저작권 및 상표권 침해를 모니터링하는데 도움이 됨</li>
</ul>
<h2 id="Step-1-Understand-the-problem-and-establish-design-scope"><a href="#Step-1-Understand-the-problem-and-establish-design-scope" class="headerlink" title="Step 1 - Understand the problem and establish design scope"></a>Step 1 - Understand the problem and establish design scope</h2><p>웹 크롤러의 동작은 단순하다.</p>
<ol>
<li>URL 집합이 주어지면 해당 URL 주소로 이동해 지정된 모든 웹 페이지를 다운로드</li>
<li>이 웹 페이지에서 URL 추출</li>
<li>다운로드 할 URL 목록에 새 URL을 추가</li>
</ol>
<p>단순한 알고리즘으로 동작하는 웹 크롤러이지만, 요구사항을 명확히 해야한다.</p>
<ul>
<li>검색 엔진 인덱싱 용도</li>
<li>한달에 10억 페이지 수집</li>
<li>HTML만 대상으로 처리</li>
<li>업데이트 된 웹 페이지도 처리 필요</li>
<li>최대 5년 저장 정책</li>
<li>중복 컨텐츠가 있는 페이지는 무시</li>
</ul>
<p>필요한 요구사항 외에도 좋은 설계를 위해서 기능의 특징을 기록해 두는 것도 중요하다.</p>
<ul>
<li>Scalability<ul>
<li>병렬화를 통한 효율성 달성</li>
</ul>
</li>
<li>Robustness<ul>
<li>잘못된 HTML, 응답하지 않는 서버, 충돌, 악성 링크와 같은 엣지 케이스의 처리 필요</li>
</ul>
</li>
<li>Politeness<ul>
<li>너무 짧은 간격으로 웹사이트에 너무 많은 요청을 하지 않아야 함</li>
</ul>
</li>
<li>Extensibility<ul>
<li>새로운 컨텐츠 유형을 지원하기 위해 최소한의 변경만 할 수 있어야 함</li>
</ul>
</li>
</ul>
<h3 id="Back-of-the-envelope-estimation"><a href="#Back-of-the-envelope-estimation" class="headerlink" title="Back of the envelope estimation"></a>Back of the envelope estimation</h3><ul>
<li>매월 10억 개의 웹 페이지가 다운로드 된다고 가정</li>
<li>QPS : 10억 / 30일 / 24시간 / 3600초 = 초당 ~400 페이지</li>
<li>peak QPS = 2 * QPS = 800</li>
<li>평균 웹 페이지 크기가 500k라고 가정</li>
<li>10억 페이지 * 500k = 500TB</li>
<li>이 데이터를 5년동안 저장한다고 가정한다면 500TB <em> 12개월 </em> 5년 = 30PB</li>
</ul>
<h2 id="Step-2-Propose-high-level-design-and-get-buy-in"><a href="#Step-2-Propose-high-level-design-and-get-buy-in" class="headerlink" title="Step 2 - Propose high-level design and get buy-in"></a>Step 2 - Propose high-level design and get buy-in</h2><p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20230402233200089.png" alt="image-20230402233200089"></p>
<p><strong>Seed URLs</strong></p>
<p>시드 URL을 크롤링 프로세스의 시작점으로 사용한다. 좋은 시드 URL은 크롤러가 가능한 한 많은 링크를 탐색하는데 활용할 수 있기 때문에 중요하다. 일반적인 전략은 URL 공간을 작은 공간으로 분할하는 것이다. 첫 번째 접근 방식은 국가마다 존재하는 인기 웹사이트를 기반으로 한다. 두 번째 방식은 쇼핑, 스포츠와 같은 주제 별로 시드 URL을 달리 선택하는 것이다.</p>
<p><strong>URL Frontier</strong></p>
<p>최신 웹 크롤러는 URL을 다운로드 할 상태와 이미 다운로드 된 상태로 나눈다. 다운로드 할 URL을 저장하는 구성요소를 URL 프론티어라고 한다. FIFO로 동작하고, 자세한 내용은 저수준 설계에서 다룬다.</p>
<p><strong>HTML Downloader</strong></p>
<p>URL 프론티어로 부터 제공받은 URL에서 HTML을 다운로드 한다.</p>
<p><strong>DNS Resolver</strong></p>
<p>웹 페이지를 다운로드 하기 전 URL은 IP 주소로 변환되어야 한다. HTML 다운로더는 DNS 리졸버를 호출해 IP 주소를 질의한다.</p>
<p><strong>Content Parser</strong></p>
<p>웹 페이지가 다운로드된 후에는 잘못된 웹 페이지가 문제를 일으킬 수 있기 때문에 구문 분석 및 유효성 검사를 수행해야 한다. 콘텐츠 파서 스텝이 추가되면 크롤링 프로세스는 느려지기 때문에 옵셔널한 구성 요소이다.</p>
<p><strong>Content Seen?</strong></p>
<p>인터넷 웹 페이지의 30%는 중복 컨텐츠로, 동일한 콘텐츠가 여러 번 저장될 수 있다. 데이터 중복을 없애고 처리 시간 단축을 위해 <code>Content Seen?</code> 스텝을 도입한다. 이 스텝은 예전에 저장된 콘텐츠의 변경을 감지하는데 사용한다. HTML을 문자별로 비교하려면 비용이 많이 들기 때문에 두 웹 페이지의 해시 값을 비교하는 작업을 통해 콘텐츠의 변경을 감지한다.</p>
<p><strong>Content Storage</strong></p>
<p>HTML 콘텐츠를 저장하기 위해 사용된다. 데이터 집합이 너무 커 대부분의 콘텐츠는 디스크에 저장되나, 인기 있는 콘텐츠는 지연 시간을 줄이기 위해 메모리에 보관한다.</p>
<p><strong>URL Extractor</strong></p>
<p>HTML에서 링크 구문을 분석하고 추출한다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20230402234150213.png" alt="image-20230402234150213"></p>
<p><strong>URL Filter</strong></p>
<p>특정 콘텐츠 유형, 파일 확장자, 오류 링크와 같은 사이트를 블랙 리스트로 등록해 제외시킨다.</p>
<p><strong>URL Seen?</strong></p>
<p>이미 방문한 URL을 추적하는데 사용된다. 서버 부하를 증가 시키고 잠재적인 무한 루프를 발생하는 URL을 여러번 추가하는 작업을 방지하는데 도움이 된다. 블룸 필터와 해시 테이블은 <code>URL Seen?</code>을 구현하는 일반적인 기술이다.</p>
<p><strong>URL Storage</strong></p>
<p>이미 방문한 URL을 저장한다.</p>
<p><strong>Web crawler workflow</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20230402234439089.png" alt="image-20230402234439089"></p>
<ol>
<li><p>URL 프론티어에 시드 URL 추가</p>
</li>
<li><p>HTML 다운로더가 URL 프론티어에서 URL 목록을 가져옴</p>
</li>
<li><p>HTML 다운로더가 DNS 리졸버에서 URL의 IP 주소를 가져와 다운로드를 시작</p>
</li>
<li><p>콘텐츠 파서가 HTML 페이지를 구문 분석하고 페이지가 잘못되었는지 확인</p>
</li>
<li><p>콘텐츠 구문 분석 및 유효성 검사가 완료되면 <code>Content Seen?</code> 구성 요소로 전달</p>
</li>
<li><p><code>Content Seen?</code>은 이미 HTML 페이지가 저장소에 있는지 확인</p>
<ul>
<li><p>저장소에 있다면 다른 URL에 있는 동일한 콘텐츠가 이미 처리되었기 때문에 HTML 페이지를 삭제</p>
</li>
<li><p>저장소에 없는 경우 콘텐츠가 링크 추출기로 전달</p>
</li>
</ul>
</li>
<li><p>링크 추출기가 HTML 페이지에서 링크를 추출</p>
</li>
<li><p>추출된 링크가 URL 필터로 전달</p>
</li>
<li><p>링크가 필터링된 후 <code>URL Seen?</code>으로 URL을 전달</p>
</li>
<li><p><code>URL Seen?</code> 컴포넌트가 이미 저장소에 있는 URL인지 확인</p>
<ul>
<li>이전에 처리되었다면 아무 작업 하지 않음</li>
<li>처리되지 않았다면 URL 프론티어에 추가</li>
</ul>
</li>
</ol>
<h2 id="Step-3-Design-deep-dive"><a href="#Step-3-Design-deep-dive" class="headerlink" title="Step 3 - Design deep dive"></a>Step 3 - Design deep dive</h2><p>저수준 디자인에서는 웹 크롤러의 중요한 구성 요소와 기술에 대해 논의한다.</p>
<h3 id="DFS-vs-BFS"><a href="#DFS-vs-BFS" class="headerlink" title="DFS vs BFS"></a>DFS vs BFS</h3><p>웹은 웹 페이지가 노드 역할을 하고 하이퍼링크가 엣지 역할을 하는 방향성 그래프로 생각할 수 있다. 그래프 탐색에 사용되는 일반적인 알고리즘은 DFS와 BFS이다. 하지만 DFS는 웹 페이지의 깊이가 매우 깊을 수 있기 때문에 일반적으로 좋은 선택이 아니다. BFS는 FIFO 큐로 구현되며 웹 크롤러에서 일반적으로 사용된다. 그러나 이 구현에는 문제가 있다.</p>
<ul>
<li><p>동일한 웹 페이지의 링크는 대부분 동일한 호스트로 다시 연결된다. 이는 크롤러가 동일한 호스트의 페이지를 처리하느라 과도한 요청이 몰릴 수 있으므로 무례한 행위로 간주된다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20230403000206939.png" alt="image-20230403000206939"></p>
</li>
<li><p>일반적인 BFS는 URL의 우선순위를 고려하지 않는다. 모든 페이지의 품질과 중요도가 동일한 수준은 아니므로 페이지 순위, 웹 트래픽, 업데이트 빈도 등에 따라 URL의 우선 순위를 정할 수 있다.</p>
</li>
</ul>
<h3 id="URL-frontier"><a href="#URL-frontier" class="headerlink" title="URL frontier"></a>URL frontier</h3><p>URL 프론티어는 위에서 언급한 문제를 해결하는데 도움이 된다. URL 프론티어는 다운로드할 URL을 저장하는 데이터 구조로 정중함, 우선순위 지정, 최신성을 보장하는 중요한 요소다.</p>
<h4 id="Politeness"><a href="#Politeness" class="headerlink" title="Politeness"></a>Politeness</h4><p>일반적으로 웹 크롤러는 단기간 내에 동일한 호스팅 서버에 너무 많은 요청을 보내지 않아야 한다. 너무 많은 요청을 전송하는 것은 무례한 행위로 간주되거나 DOS 공격으로 취급되기도 한다. 정중함을 적용하는 일반적인 아이디어는 동일한 호스트에서 한 번에 한 페이지씩 다운로드하는 것이다. 두 다운로드 작업 사이에 지연 시간을 추가할 수 있다. 이런 조건은 웹사이트 호스트 이름을 기반으로 한 FIFO 대기열로부터 다운로드에 작업을 할당함으로 써 구현된다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20230403001313687.png" alt="image-20230403001313687"></p>
<ul>
<li>Queue router : 각 큐에 동일한 호스트의 URL만 포함되도록 한다</li>
<li>Mapping table : 각 호스트를 큐에 매핑한다</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left"><strong>Host</strong></th>
<th style="text-align:left"><strong>Queue</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">wikipedia.com</td>
<td style="text-align:left">b1</td>
</tr>
<tr>
<td style="text-align:left">apple.com</td>
<td style="text-align:left">b2</td>
</tr>
<tr>
<td style="text-align:left">…</td>
<td style="text-align:left">…</td>
</tr>
<tr>
<td style="text-align:left">nike.com</td>
<td style="text-align:left">bn</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>FIFO Queue b1, b2 ~ bn : 각 대기열에는 동일한 호스트의 URL이 포함된다</li>
<li>Queue selector : 각 워커 스레드는 FIFO 대기열에 매핑되며 해당 대기열에서만 URL을 다운로드 한다. 큐 선택 로직은 Queue selector에 의해 이루어진다</li>
<li>Worker thread 1 to N : 각 워커 스레드는 동일한 호스트에서 웹 페이지를 하나씩 다운로드 한다. 두 다운로드 작업 사이에 지연을 추가할 수 있다</li>
</ul>
<h4 id="Priority"><a href="#Priority" class="headerlink" title="Priority"></a>Priority</h4><p>페이지 랭크, 웹사이트 트래픽, 업데이트 빈도 등으로 측정할 수 있는 유용성을 기준으로 URL의 우선순위를 정한다. <code>Prioritizer</code>는 URL의 우선순위를 처리하는 컴포넌트다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20230403002813434.png" alt="image-20230403002813434"></p>
<ul>
<li>Prioritizer : URL을 입력으로 받아 우선순위를 계산한다</li>
<li>Queue f1 to fn : 각 대기열에는 우선순위가 할당되어 있다. 우선순위가 높은 큐가 더 높은 확률로 선택된다</li>
<li>Queue selector : 우선순위가 높은 큐에 편향된 방법으로 큐를 무작위 선택한다</li>
</ul>
<p>아래는 URL 프론티어의 설계로 우선 순위를 관리하는 front queue와 공손함을 관리하는 back queue로 구성된다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20230403003103616.png" alt="image-20230403003103616"></p>
<h4 id="Freshness"><a href="#Freshness" class="headerlink" title="Freshness"></a>Freshness</h4><p>웹 크롤러는 데이터 집합을 최신 상태로 유지하기 위해 주기적으로 다운로드한 페이지를 다시 크롤링 해야 한다. 모든 URL을 다시 크롤링하려면 비용이 많이 소모되기 때문에 최신성을 최적화하기 위한 몇 가지 전략을 고려해야 한다.</p>
<ul>
<li>웹 페이지 업데이트 기록을 기반으로 다시 크롤링</li>
<li>URL의 우선순위를 정하고 중요한 페이지를 먼저, 더 자주 다시 크롤링</li>
</ul>
<h4 id="Storage-for-URL-Frontier"><a href="#Storage-for-URL-Frontier" class="headerlink" title="Storage for URL Frontier"></a>Storage for URL Frontier</h4><p>실제 검색 엔진의 크롤링에서 프론티어가 관리하는 URL 집합은 매우 클 수 있기 때문에 모든것을 메모리에 저장하는 것은 내구성이나 확장성의 측면에서 좋지 않다. 그렇다고 모든 정보를 디스크에 저장하기에는 이 스텝에서 병목 현상이 발생할 수 있게 된다. 이를 위해 대부분의 데이터는 디스크에 저장하되, queue의 enqueue / dequeue 작업을 버퍼를 통해 디스크 엑세스를 줄일 수 있다. 버퍼는 주기적으로 디스크에 기록된다.</p>
<h3 id="HTML-Downloader"><a href="#HTML-Downloader" class="headerlink" title="HTML Downloader"></a>HTML Downloader</h3><h5 id="Robots-txt"><a href="#Robots-txt" class="headerlink" title="Robots.txt"></a>Robots.txt</h5><p>Robots Exclusion 프로토콜이라고 하는 Robots.txt는 웹 사이트가 크롤러와 통신하는데 사용하는 표준이다. 이 파일은 크롤러가 다운로드할 수 있는 페이지를 지정한다. 크롤러는 웹사이트를 크롤링하기 전에 먼저 robots.txt를 확인하고 규칙을 따라야 한다. robots.txt 파일의 반복 다운로드를 피하기 위해 해당 파일의 결과를 캐시해둔다. 이 파일을 주기적으로 다운로드해 캐시에 저장한다.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">User-agent: Googlebot</span><br><span class="line">Disallow: /creatorhub/\*</span><br><span class="line">Disallow: /rss/people/\*/reviews</span><br><span class="line">Disallow: /gp/pdp/rss/\*/reviews</span><br><span class="line">Disallow: /gp/cdp/member-reviews/</span><br><span class="line">Disallow: /gp/aw/cr/</span><br></pre></td></tr></table></figure>
<h5 id="Performance-optimization"><a href="#Performance-optimization" class="headerlink" title="Performance optimization"></a>Performance optimization</h5><ol>
<li>분산 크롤링</li>
</ol>
<p>고성능을 달성하기 위해 크롤링 작업이 여러 서버로 분산되고 각 서버는 여러 스레드를 실행한다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20230403013407563.png" alt="image-20230403013407563"></p>
<ol>
<li>DNS Resolver 캐시</li>
</ol>
<p>많은 DNS 인터페이스의 동기적 특성으로 인해 DNS Resolver는 크롤러의 병목 현상중 하나다. DNS 캐시를 유지해 DNS를 자주 호출하지 않도록 하는 것은 속도 최적화를 위한 기술이다.</p>
<ol>
<li>지역성</li>
</ol>
<p>크롤링 서버를 지리적으로 분산시키면 크롤러 서버가 웹 사이트 호스트에 가까울수록 단축된 다운로드 시간을 경험할 수 있다.</p>
<ol>
<li>짧은 타임아웃</li>
</ol>
<p>일부 웹 서버는 느리거나 아예 응답하지 않을 수 있다. 긴 대기시간을 회피하기 위해 최대 대기시간을 지정한다.</p>
<h3 id="Robustness"><a href="#Robustness" class="headerlink" title="Robustness"></a>Robustness</h3><ul>
<li>일관된 해싱 : 다운로더간에 부하를 분산하거나 새 다운로더 서버를 추가하거나 제거할 수 있다.</li>
<li>크롤링 상태 및 데이터 저장 : 장애 방지를 위해 크롤링 상태와 데이터를 스토리지에 기록한다. 중단된 크롤링은 저장된 상태와 데이터를 로드해 다시 시작한다.</li>
<li>예외 처리 : 크롤러는 시스템을 중단시키지 않고 예외를 원활하게 처리해야 한다.</li>
<li>데이터 유효성 검사 : 시스템 오류를 방지하기 위한 중요한 조치다.</li>
</ul>
<h3 id="Extensibility"><a href="#Extensibility" class="headerlink" title="Extensibility"></a>Extensibility</h3><p>위의 고수준 설계안은 크롤러에 새 모듈을 연결하여 확장성을 보장할 수 있다.</p>
<p><img src="https://cdn.jsdelivr.net/gh/SongHayoung/image@master/uPic/image-20230403013906968.png" alt="image-20230403013906968"></p>
<h3 id="Detect-and-avoid-problematic-content"><a href="#Detect-and-avoid-problematic-content" class="headerlink" title="Detect and avoid problematic content"></a>Detect and avoid problematic content</h3><ol>
<li><p>중복 콘텐츠<br>해시 또는 체크섬을 통해 중복을 감지한다.</p>
</li>
<li><p>스파이더 트랩</p>
</li>
</ol>
<p>스파이더 트랩은 크롤러를 무한 루프에 빠트리는 웹페이지다. <code>http://www.spidertrapexample.com/foo/bar/foo/bar/foo/bar/...</code></p>
<p>이런 스파이더 트랩은 URL의 최대 길이를 설정해 피할 수 있다. 만능 스파이더 트랩을 개발하는건 어려운 일이지만, 수동으로 스파이더 트랩을 확인하고 URL 필터에서 해당 웹사이트를 제외할 수 있다.</p>
<ol>
<li>데이터 노이즈</li>
</ol>
<p>광고, 스팸 URL등 일부 콘텐츠는 가치가 없기 때문에 가능하면 제거해야 한다.</p>
<h2 id="Step-4-Wrap-up"><a href="#Step-4-Wrap-up" class="headerlink" title="Step 4 - Wrap up"></a>Step 4 - Wrap up</h2><p>크롤링을 위한 중요한 요소인 확장성, 정중함, 견고성 등에 대해 논의했다. 그 외에도 논의할 주제들은 아래와 같다.</p>
<ul>
<li>서버 사이드 랜더링<ul>
<li>많은 웹사이트가 JS, AJAX 등을 사용해 링크를 즉석에서 생성한다. 이 문제를 해결하기 위해 페이지 파싱 전 서버 사이드 랜더링을 수행한다.</li>
</ul>
</li>
<li>원치 않는 페이지 필터링<ul>
<li>스팸 방지 구성 요소를 통해 품질 낮은 페이지와 스팸 페이지를 필터링한다.</li>
</ul>
</li>
<li>데이터베이스 복제 및 샤딩<ul>
<li>복제나 샤딩같은 기술은 데이터 레이어의 가용성, 확장성, 안정성을 개선하는데 도움이 된다.</li>
</ul>
</li>
<li>수평적 확장<ul>
<li>크롤링 서버의 수평적 확장 핵심은 크롤링 서버를 stateless로 만드는 것이다.</li>
</ul>
</li>
</ul>
<!-- flag of hidden posts --></div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Song Hayoung</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://songhayoung.github.io/2023/04/02/System%20Design/ByteByteGo/book/design-a-web-crawler/">https://songhayoung.github.io/2023/04/02/System%20Design/ByteByteGo/book/design-a-web-crawler/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/System-Design/">System Design</a></div><nav id="pagination"></nav><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: '3604b61642355579f55e',
  clientSecret: 'f552120f18ac5aee3f6297e05e97d94c0a25cd4b',
  repo: 'SongHayoung.github.io',
  owner: 'SongHayoung',
  admin: 'SongHayoung',
  id: md5(decodeURI(location.pathname)),
  language: 'en'
})
gitalk.render('gitalk-container')</script></div></div><footer class="footer-bg" style="background-image: url(https://xxxx.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2020 - 2024 By Song Hayoung</div><div class="framework-info"><span>Driven - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">Learning how to walk slowly to not miss important things</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.7.0"></script><script src="/js/fancybox.js?version=1.7.0"></script><script src="/js/sidebar.js?version=1.7.0"></script><script src="/js/copy.js?version=1.7.0"></script><script src="/js/fireworks.js?version=1.7.0"></script><script src="/js/transition.js?version=1.7.0"></script><script src="/js/scroll.js?version=1.7.0"></script><script src="/js/head.js?version=1.7.0"></script><script src="/js/search/algolia.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="algolia-search"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>